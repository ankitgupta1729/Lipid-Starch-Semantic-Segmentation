{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2bd89d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import img_as_float\n",
    "from  matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4fb36996",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image=io.imread('original_images/7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "a48fc94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "uint8\n",
      "(1059, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "print(type(my_image)) # image is a numpy array\n",
    "print(my_image.dtype) # image is of dtype\n",
    "print(my_image.shape) # image is of shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba67c41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "853a8d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simple_multi_unet_model import multi_unet_model #Uses softmax \n",
    "\n",
    "from keras.utils import normalize\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7ec1de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass Semantic Segmentation on images\n",
    "SIZE_X=128\n",
    "SIZE_Y=128\n",
    "n_classes=4\n",
    "train_images=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b44853c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for directory_path in glob.glob(\"original_images/\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, 0)       \n",
    "        img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "        train_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "ae4f2262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "aae8f482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a7d8ad43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8e3c613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert list to array for machine learning processing        \n",
    "train_images = np.array(train_images)\n",
    "\n",
    "#Capture mask/label info as a list\n",
    "train_masks = [] \n",
    "for directory_path in glob.glob(\"masked_images/\"):\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        mask = cv2.imread(mask_path, 0)       \n",
    "        mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation\n",
    "        train_masks.append(mask)\n",
    "        \n",
    "#Convert list to array for machine learning processing          \n",
    "train_masks = np.array(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9cb70ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4c575119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "def808d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b18eb149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  38,  75, 113], dtype=uint8)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e551ae11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ankit/Desktop/ml/Tensorflow_ENV/tfenv/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode labels... but multi dim array so need to flatten, encode and reshape\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = train_masks.shape\n",
    "train_masks_reshaped = train_masks.reshape(-1,1)\n",
    "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
    "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(train_masks_encoded_original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d4ce9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, h, w = train_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6f4b1d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f4424592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7d7eb57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b1f87cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 128, 128)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks_encoded_original_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "20523aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.expand_dims(train_images, axis=3)\n",
    "train_images = normalize(train_images, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2a4390d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 128, 128, 1)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5d7b04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5dd623b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 128, 128, 1)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5ffd52fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class values in the dataset are ...  [0 1 2 3]\n"
     ]
    }
   ],
   "source": [
    "#Create a subset of data for quick testing\n",
    "#Picking 10% for testing and remaining for training\n",
    "from sklearn.model_selection import train_test_split\n",
    "X1, X_test, y1, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)\n",
    "\n",
    "#Further split training data t a smaller subset for quick testing of models\n",
    "X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background/few unlabeled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d45f0719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "56466ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 128, 128, 4)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c07167fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6b2a7282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 128, 128, 4)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6c7b70bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights are...: [ 0.41695169  0.73766181 14.24794768  5.68762497]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',classes=np.unique(train_masks_reshaped_encoded),y=train_masks_reshaped_encoded)\n",
    "print(\"Class weights are...:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828af9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 128, 128, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 128, 128, 16  160         ['input_9[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_72 (Dropout)           (None, 128, 128, 16  0           ['conv2d_152[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 128, 128, 16  2320        ['dropout_72[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_32 (MaxPooling2D  (None, 64, 64, 16)  0           ['conv2d_153[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 64, 64, 32)   4640        ['max_pooling2d_32[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_73 (Dropout)           (None, 64, 64, 32)   0           ['conv2d_154[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 64, 64, 32)   9248        ['dropout_73[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_33 (MaxPooling2D  (None, 32, 32, 32)  0           ['conv2d_155[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 32, 32, 64)   18496       ['max_pooling2d_33[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 32, 32, 64)   0           ['conv2d_156[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 32, 32, 64)   36928       ['dropout_74[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_34 (MaxPooling2D  (None, 16, 16, 64)  0           ['conv2d_157[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 16, 16, 128)  73856       ['max_pooling2d_34[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_75 (Dropout)           (None, 16, 16, 128)  0           ['conv2d_158[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 16, 16, 128)  147584      ['dropout_75[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_35 (MaxPooling2D  (None, 8, 8, 128)   0           ['conv2d_159[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 8, 8, 256)    295168      ['max_pooling2d_35[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_76 (Dropout)           (None, 8, 8, 256)    0           ['conv2d_160[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 8, 8, 256)    590080      ['dropout_76[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_32 (Conv2DTra  (None, 16, 16, 128)  131200     ['conv2d_161[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 16, 16, 256)  0           ['conv2d_transpose_32[0][0]',    \n",
      "                                                                  'conv2d_159[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 16, 16, 128)  295040      ['concatenate_32[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_77 (Dropout)           (None, 16, 16, 128)  0           ['conv2d_162[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)            (None, 16, 16, 128)  147584      ['dropout_77[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_33 (Conv2DTra  (None, 32, 32, 64)  32832       ['conv2d_163[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 32, 32, 128)  0           ['conv2d_transpose_33[0][0]',    \n",
      "                                                                  'conv2d_157[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)            (None, 32, 32, 64)   73792       ['concatenate_33[0][0]']         \n",
      "                                                                                                  \n",
      " dropout_78 (Dropout)           (None, 32, 32, 64)   0           ['conv2d_164[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)            (None, 32, 32, 64)   36928       ['dropout_78[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_34 (Conv2DTra  (None, 64, 64, 32)  8224        ['conv2d_165[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 64, 64, 64)   0           ['conv2d_transpose_34[0][0]',    \n",
      "                                                                  'conv2d_155[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)            (None, 64, 64, 32)   18464       ['concatenate_34[0][0]']         \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_79 (Dropout)           (None, 64, 64, 32)   0           ['conv2d_166[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)            (None, 64, 64, 32)   9248        ['dropout_79[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_35 (Conv2DTra  (None, 128, 128, 16  2064       ['conv2d_167[0][0]']             \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_35 (Concatenate)   (None, 128, 128, 32  0           ['conv2d_transpose_35[0][0]',    \n",
      "                                )                                 'conv2d_153[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)            (None, 128, 128, 16  4624        ['concatenate_35[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_80 (Dropout)           (None, 128, 128, 16  0           ['conv2d_168[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)            (None, 128, 128, 16  2320        ['dropout_80[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)            (None, 128, 128, 4)  68          ['conv2d_169[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,940,868\n",
      "Trainable params: 1,940,868\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/1000\n",
      "2/2 [==============================] - 4s 542ms/step - loss: 1.3632 - accuracy: 0.4483 - val_loss: 1.2687 - val_accuracy: 0.4891\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 1.3469 - accuracy: 0.5365 - val_loss: 1.2310 - val_accuracy: 0.4806\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 1.2116 - accuracy: 0.5502 - val_loss: 1.1627 - val_accuracy: 0.4716\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 1.1381 - accuracy: 0.5519 - val_loss: 1.0341 - val_accuracy: 0.4875\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 1.0136 - accuracy: 0.5514 - val_loss: 0.9594 - val_accuracy: 0.4715\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 1.0607 - accuracy: 0.5588 - val_loss: 0.9672 - val_accuracy: 0.4754\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.9671 - accuracy: 0.5724 - val_loss: 0.9731 - val_accuracy: 0.4784\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.9569 - accuracy: 0.5773 - val_loss: 0.9694 - val_accuracy: 0.4815\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.9509 - accuracy: 0.5799 - val_loss: 0.9702 - val_accuracy: 0.4830\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.9517 - accuracy: 0.5818 - val_loss: 0.9726 - val_accuracy: 0.4853\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.9525 - accuracy: 0.5829 - val_loss: 0.9673 - val_accuracy: 0.4853\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.9448 - accuracy: 0.5832 - val_loss: 0.9580 - val_accuracy: 0.4868\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.9335 - accuracy: 0.5830 - val_loss: 0.9492 - val_accuracy: 0.4878\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.9263 - accuracy: 0.5821 - val_loss: 0.9408 - val_accuracy: 0.4885\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.9216 - accuracy: 0.5812 - val_loss: 0.9335 - val_accuracy: 0.4888\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.9177 - accuracy: 0.5815 - val_loss: 0.9309 - val_accuracy: 0.4890\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.9160 - accuracy: 0.5835 - val_loss: 0.9369 - val_accuracy: 0.4890\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.9152 - accuracy: 0.5854 - val_loss: 0.9420 - val_accuracy: 0.4891\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 1s 138ms/step - loss: 0.9104 - accuracy: 0.5864 - val_loss: 0.9340 - val_accuracy: 0.4891\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.9035 - accuracy: 0.5872 - val_loss: 0.9160 - val_accuracy: 0.4892\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.8929 - accuracy: 0.5917 - val_loss: 0.8955 - val_accuracy: 0.5024\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 1s 151ms/step - loss: 0.8843 - accuracy: 0.6043 - val_loss: 0.8817 - val_accuracy: 0.5424\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.8709 - accuracy: 0.6230 - val_loss: 0.8566 - val_accuracy: 0.5943\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 1s 245ms/step - loss: 0.8663 - accuracy: 0.6391 - val_loss: 0.8625 - val_accuracy: 0.5753\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 1s 167ms/step - loss: 0.8294 - accuracy: 0.6466 - val_loss: 0.8875 - val_accuracy: 0.5771\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.8390 - accuracy: 0.6437 - val_loss: 0.8025 - val_accuracy: 0.6274\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 1s 163ms/step - loss: 0.8337 - accuracy: 0.6445 - val_loss: 0.8438 - val_accuracy: 0.5986\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.7866 - accuracy: 0.6650 - val_loss: 0.7515 - val_accuracy: 0.6525\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 1s 129ms/step - loss: 0.7463 - accuracy: 0.6864 - val_loss: 0.7876 - val_accuracy: 0.6423\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.7406 - accuracy: 0.6967 - val_loss: 0.7212 - val_accuracy: 0.6764\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.7253 - accuracy: 0.7090 - val_loss: 0.7860 - val_accuracy: 0.6357\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.7334 - accuracy: 0.6925 - val_loss: 0.7321 - val_accuracy: 0.6598\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.7381 - accuracy: 0.6949 - val_loss: 0.7988 - val_accuracy: 0.6331\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.7328 - accuracy: 0.6971 - val_loss: 0.7204 - val_accuracy: 0.6981\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.6924 - accuracy: 0.7389 - val_loss: 0.8198 - val_accuracy: 0.6450\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.7026 - accuracy: 0.7218 - val_loss: 0.7701 - val_accuracy: 0.6513\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 1s 155ms/step - loss: 0.7097 - accuracy: 0.6998 - val_loss: 0.8311 - val_accuracy: 0.6455\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 1s 180ms/step - loss: 0.6914 - accuracy: 0.7305 - val_loss: 0.7096 - val_accuracy: 0.7155\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 0.6328 - accuracy: 0.7725 - val_loss: 0.6670 - val_accuracy: 0.7515\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.6106 - accuracy: 0.7932 - val_loss: 0.8690 - val_accuracy: 0.6752\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.6871 - accuracy: 0.7490 - val_loss: 0.7145 - val_accuracy: 0.7181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.6977 - accuracy: 0.7369 - val_loss: 0.9005 - val_accuracy: 0.6827\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 0.6955 - accuracy: 0.7578 - val_loss: 0.6825 - val_accuracy: 0.7574\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.6134 - accuracy: 0.7923 - val_loss: 0.7429 - val_accuracy: 0.7280\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 1s 156ms/step - loss: 0.6143 - accuracy: 0.7914 - val_loss: 0.6518 - val_accuracy: 0.7618\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 1s 163ms/step - loss: 0.5694 - accuracy: 0.8053 - val_loss: 0.6656 - val_accuracy: 0.7682\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 1s 237ms/step - loss: 0.5594 - accuracy: 0.8174 - val_loss: 0.8663 - val_accuracy: 0.7221\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 1s 218ms/step - loss: 0.6364 - accuracy: 0.7988 - val_loss: 0.5995 - val_accuracy: 0.8065\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 1s 156ms/step - loss: 0.5839 - accuracy: 0.8026 - val_loss: 1.0822 - val_accuracy: 0.6644\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 1s 202ms/step - loss: 0.7837 - accuracy: 0.7607 - val_loss: 0.5891 - val_accuracy: 0.8170\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 0.6523 - accuracy: 0.7827 - val_loss: 0.6488 - val_accuracy: 0.7905\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.5648 - accuracy: 0.8255 - val_loss: 0.6624 - val_accuracy: 0.7648\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 1s 152ms/step - loss: 0.5603 - accuracy: 0.8165 - val_loss: 0.7333 - val_accuracy: 0.7330\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.6214 - accuracy: 0.7954 - val_loss: 0.6896 - val_accuracy: 0.7310\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 1s 170ms/step - loss: 0.6117 - accuracy: 0.7818 - val_loss: 0.6317 - val_accuracy: 0.7684\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.5581 - accuracy: 0.8107 - val_loss: 0.6167 - val_accuracy: 0.7895\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.5313 - accuracy: 0.8238 - val_loss: 0.6265 - val_accuracy: 0.7916\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.5579 - accuracy: 0.8142 - val_loss: 0.5682 - val_accuracy: 0.8217\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.5324 - accuracy: 0.8220 - val_loss: 0.7106 - val_accuracy: 0.7813\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.5827 - accuracy: 0.8100 - val_loss: 0.5799 - val_accuracy: 0.8253\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 0.5129 - accuracy: 0.8289 - val_loss: 0.6621 - val_accuracy: 0.7912\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 1s 138ms/step - loss: 0.5191 - accuracy: 0.8294 - val_loss: 0.5217 - val_accuracy: 0.8274\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.5189 - accuracy: 0.8239 - val_loss: 0.7171 - val_accuracy: 0.7657\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.5071 - accuracy: 0.8344 - val_loss: 0.5700 - val_accuracy: 0.8244\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.4959 - accuracy: 0.8317 - val_loss: 0.5968 - val_accuracy: 0.8293\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 0.4859 - accuracy: 0.8328 - val_loss: 0.7607 - val_accuracy: 0.7441\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.5291 - accuracy: 0.8176 - val_loss: 0.5476 - val_accuracy: 0.8359\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.4739 - accuracy: 0.8368 - val_loss: 0.5473 - val_accuracy: 0.8354\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.4726 - accuracy: 0.8369 - val_loss: 0.7193 - val_accuracy: 0.8037\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 1s 138ms/step - loss: 0.4721 - accuracy: 0.8474 - val_loss: 0.5898 - val_accuracy: 0.8359\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.4481 - accuracy: 0.8459 - val_loss: 0.6218 - val_accuracy: 0.8288\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.4248 - accuracy: 0.8578 - val_loss: 0.6039 - val_accuracy: 0.8314\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 1s 336ms/step - loss: 0.4126 - accuracy: 0.8597 - val_loss: 0.5808 - val_accuracy: 0.8380\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 1s 268ms/step - loss: 0.4144 - accuracy: 0.8603 - val_loss: 0.5739 - val_accuracy: 0.8413\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 1s 269ms/step - loss: 0.4130 - accuracy: 0.8612 - val_loss: 0.5798 - val_accuracy: 0.8406\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.3959 - accuracy: 0.8676 - val_loss: 0.5384 - val_accuracy: 0.8513\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 1s 219ms/step - loss: 0.3974 - accuracy: 0.8643 - val_loss: 0.5807 - val_accuracy: 0.8492\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.3920 - accuracy: 0.8690 - val_loss: 0.6405 - val_accuracy: 0.8314\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 1s 242ms/step - loss: 0.3894 - accuracy: 0.8701 - val_loss: 0.6524 - val_accuracy: 0.8256\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 1s 220ms/step - loss: 0.3977 - accuracy: 0.8669 - val_loss: 0.5258 - val_accuracy: 0.8571\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.3799 - accuracy: 0.8653 - val_loss: 0.6395 - val_accuracy: 0.8418\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 1s 138ms/step - loss: 0.3528 - accuracy: 0.8788 - val_loss: 0.5898 - val_accuracy: 0.8357\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.4036 - accuracy: 0.8579 - val_loss: 0.7377 - val_accuracy: 0.8145\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.4313 - accuracy: 0.8517 - val_loss: 0.5773 - val_accuracy: 0.8345\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.3939 - accuracy: 0.8659 - val_loss: 0.5909 - val_accuracy: 0.8512\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.3863 - accuracy: 0.8757 - val_loss: 0.6744 - val_accuracy: 0.8379\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.3974 - accuracy: 0.8706 - val_loss: 0.6598 - val_accuracy: 0.8045\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.4580 - accuracy: 0.8372 - val_loss: 0.6023 - val_accuracy: 0.8311\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 1s 179ms/step - loss: 0.3701 - accuracy: 0.8682 - val_loss: 0.5867 - val_accuracy: 0.8385\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.3846 - accuracy: 0.8675 - val_loss: 0.5242 - val_accuracy: 0.8508\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.3497 - accuracy: 0.8792 - val_loss: 0.5955 - val_accuracy: 0.8419\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.3377 - accuracy: 0.8816 - val_loss: 0.6768 - val_accuracy: 0.8407\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.3302 - accuracy: 0.8862 - val_loss: 0.5680 - val_accuracy: 0.8524\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 1s 170ms/step - loss: 0.3139 - accuracy: 0.8913 - val_loss: 0.5942 - val_accuracy: 0.8441\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 1s 194ms/step - loss: 0.3148 - accuracy: 0.8919 - val_loss: 0.5423 - val_accuracy: 0.8648\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.3081 - accuracy: 0.8922 - val_loss: 0.6021 - val_accuracy: 0.8617\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 1s 203ms/step - loss: 0.2847 - accuracy: 0.8993 - val_loss: 0.6270 - val_accuracy: 0.8498\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 1s 157ms/step - loss: 0.2963 - accuracy: 0.8964 - val_loss: 0.6146 - val_accuracy: 0.8604\n",
      "Epoch 99/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 190ms/step - loss: 0.2771 - accuracy: 0.9004 - val_loss: 0.6430 - val_accuracy: 0.8600\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 1s 247ms/step - loss: 0.2801 - accuracy: 0.9014 - val_loss: 0.7511 - val_accuracy: 0.8458\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 1s 224ms/step - loss: 0.2682 - accuracy: 0.9063 - val_loss: 0.8293 - val_accuracy: 0.8375\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 1s 154ms/step - loss: 0.2786 - accuracy: 0.9031 - val_loss: 0.6248 - val_accuracy: 0.8578\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.2623 - accuracy: 0.9053 - val_loss: 0.6558 - val_accuracy: 0.8461\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 1s 218ms/step - loss: 0.2840 - accuracy: 0.8985 - val_loss: 0.5514 - val_accuracy: 0.8607\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 1s 227ms/step - loss: 0.2738 - accuracy: 0.9022 - val_loss: 0.7394 - val_accuracy: 0.8342\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 1s 219ms/step - loss: 0.2851 - accuracy: 0.8991 - val_loss: 0.6189 - val_accuracy: 0.8321\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 1s 258ms/step - loss: 0.2963 - accuracy: 0.8925 - val_loss: 0.6924 - val_accuracy: 0.8378\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 1s 229ms/step - loss: 0.2580 - accuracy: 0.9089 - val_loss: 0.6627 - val_accuracy: 0.8487\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.2527 - accuracy: 0.9089 - val_loss: 0.6376 - val_accuracy: 0.8497\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.2373 - accuracy: 0.9161 - val_loss: 0.6578 - val_accuracy: 0.8552\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 1s 151ms/step - loss: 0.2288 - accuracy: 0.9178 - val_loss: 0.6442 - val_accuracy: 0.8580\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.2347 - accuracy: 0.9159 - val_loss: 0.5860 - val_accuracy: 0.8507\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.2383 - accuracy: 0.9135 - val_loss: 0.6514 - val_accuracy: 0.8460\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.2337 - accuracy: 0.9151 - val_loss: 0.5919 - val_accuracy: 0.8550\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 0.2324 - accuracy: 0.9167 - val_loss: 0.8724 - val_accuracy: 0.7969\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.2835 - accuracy: 0.8981 - val_loss: 0.7275 - val_accuracy: 0.8508\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 1s 214ms/step - loss: 0.2432 - accuracy: 0.9168 - val_loss: 0.6622 - val_accuracy: 0.8498\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.2264 - accuracy: 0.9174 - val_loss: 0.7713 - val_accuracy: 0.8356\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.2319 - accuracy: 0.9158 - val_loss: 0.6549 - val_accuracy: 0.8540\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 1s 134ms/step - loss: 0.2268 - accuracy: 0.9196 - val_loss: 0.6473 - val_accuracy: 0.8456\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.2121 - accuracy: 0.9228 - val_loss: 0.8055 - val_accuracy: 0.8224\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 1s 111ms/step - loss: 0.2353 - accuracy: 0.9156 - val_loss: 0.5896 - val_accuracy: 0.8523\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.2028 - accuracy: 0.9249 - val_loss: 0.5874 - val_accuracy: 0.8588\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.2002 - accuracy: 0.9256 - val_loss: 0.5433 - val_accuracy: 0.8623\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.2176 - accuracy: 0.9199 - val_loss: 0.6861 - val_accuracy: 0.8441\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.1932 - accuracy: 0.9290 - val_loss: 0.7920 - val_accuracy: 0.8380\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.1972 - accuracy: 0.9285 - val_loss: 0.7185 - val_accuracy: 0.8384\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.1915 - accuracy: 0.9289 - val_loss: 0.7517 - val_accuracy: 0.8428\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.1909 - accuracy: 0.9287 - val_loss: 0.6518 - val_accuracy: 0.8497\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.1975 - accuracy: 0.9267 - val_loss: 0.7812 - val_accuracy: 0.8281\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 1s 156ms/step - loss: 0.1897 - accuracy: 0.9287 - val_loss: 0.7317 - val_accuracy: 0.8432\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.1789 - accuracy: 0.9334 - val_loss: 0.7329 - val_accuracy: 0.8440\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 1s 156ms/step - loss: 0.1675 - accuracy: 0.9369 - val_loss: 0.8043 - val_accuracy: 0.8386\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 1s 193ms/step - loss: 0.1695 - accuracy: 0.9365 - val_loss: 0.7444 - val_accuracy: 0.8431\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.1674 - accuracy: 0.9366 - val_loss: 0.8362 - val_accuracy: 0.8406\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.1680 - accuracy: 0.9371 - val_loss: 0.8345 - val_accuracy: 0.8417\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.1626 - accuracy: 0.9382 - val_loss: 0.8156 - val_accuracy: 0.8430\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 1s 140ms/step - loss: 0.1645 - accuracy: 0.9385 - val_loss: 0.7895 - val_accuracy: 0.8454\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 1s 131ms/step - loss: 0.1576 - accuracy: 0.9402 - val_loss: 0.8432 - val_accuracy: 0.8389\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.1649 - accuracy: 0.9371 - val_loss: 0.7962 - val_accuracy: 0.8388\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 1s 170ms/step - loss: 0.1576 - accuracy: 0.9399 - val_loss: 0.8946 - val_accuracy: 0.8331\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 1s 166ms/step - loss: 0.1595 - accuracy: 0.9390 - val_loss: 0.7879 - val_accuracy: 0.8407\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 1s 152ms/step - loss: 0.1515 - accuracy: 0.9426 - val_loss: 0.8177 - val_accuracy: 0.8441\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.1486 - accuracy: 0.9437 - val_loss: 0.7712 - val_accuracy: 0.8437\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.1506 - accuracy: 0.9422 - val_loss: 0.8134 - val_accuracy: 0.8365\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.1461 - accuracy: 0.9446 - val_loss: 0.8330 - val_accuracy: 0.8417\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.1552 - accuracy: 0.9415 - val_loss: 0.9066 - val_accuracy: 0.8252\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 0.1573 - accuracy: 0.9407 - val_loss: 0.8973 - val_accuracy: 0.8421\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1527 - accuracy: 0.9433 - val_loss: 0.8718 - val_accuracy: 0.8338\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.1471 - accuracy: 0.9439 - val_loss: 0.8577 - val_accuracy: 0.8404\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1438 - accuracy: 0.9451 - val_loss: 1.0554 - val_accuracy: 0.8316\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.1540 - accuracy: 0.9415 - val_loss: 0.8302 - val_accuracy: 0.8333\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.1671 - accuracy: 0.9366 - val_loss: 0.9845 - val_accuracy: 0.8310\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1468 - accuracy: 0.9435 - val_loss: 0.8960 - val_accuracy: 0.8368\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.1417 - accuracy: 0.9456 - val_loss: 0.9258 - val_accuracy: 0.8269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1396 - accuracy: 0.9469 - val_loss: 0.8924 - val_accuracy: 0.8378\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.1325 - accuracy: 0.9496 - val_loss: 0.9271 - val_accuracy: 0.8411\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.1315 - accuracy: 0.9495 - val_loss: 0.9254 - val_accuracy: 0.8350\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 1s 178ms/step - loss: 0.1269 - accuracy: 0.9513 - val_loss: 0.9674 - val_accuracy: 0.8290\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.1324 - accuracy: 0.9496 - val_loss: 0.8679 - val_accuracy: 0.8417\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 1s 129ms/step - loss: 0.1385 - accuracy: 0.9458 - val_loss: 1.0291 - val_accuracy: 0.8231\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.1540 - accuracy: 0.9404 - val_loss: 0.8322 - val_accuracy: 0.8342\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 1s 173ms/step - loss: 0.1402 - accuracy: 0.9462 - val_loss: 0.9577 - val_accuracy: 0.8357\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1240 - accuracy: 0.9521 - val_loss: 0.9182 - val_accuracy: 0.8361\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1188 - accuracy: 0.9546 - val_loss: 0.8614 - val_accuracy: 0.8353\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 1s 161ms/step - loss: 0.1394 - accuracy: 0.9466 - val_loss: 1.1329 - val_accuracy: 0.8153\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.1539 - accuracy: 0.9410 - val_loss: 0.8857 - val_accuracy: 0.8329\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.1348 - accuracy: 0.9479 - val_loss: 0.8989 - val_accuracy: 0.8256\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1331 - accuracy: 0.9496 - val_loss: 0.8859 - val_accuracy: 0.8359\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.1220 - accuracy: 0.9535 - val_loss: 0.7729 - val_accuracy: 0.8460\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.1634 - accuracy: 0.9394 - val_loss: 0.9633 - val_accuracy: 0.8266\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.1255 - accuracy: 0.9527 - val_loss: 0.9741 - val_accuracy: 0.8269\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1201 - accuracy: 0.9549 - val_loss: 0.9008 - val_accuracy: 0.8344\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.1324 - accuracy: 0.9494 - val_loss: 1.0623 - val_accuracy: 0.8110\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.1387 - accuracy: 0.9472 - val_loss: 0.7858 - val_accuracy: 0.8446\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1296 - accuracy: 0.9505 - val_loss: 0.8667 - val_accuracy: 0.8497\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.1596 - accuracy: 0.9412 - val_loss: 0.7949 - val_accuracy: 0.8354\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.1594 - accuracy: 0.9396 - val_loss: 0.8613 - val_accuracy: 0.8385\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1371 - accuracy: 0.9488 - val_loss: 0.9318 - val_accuracy: 0.8214\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.1296 - accuracy: 0.9511 - val_loss: 0.9042 - val_accuracy: 0.8296\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.1269 - accuracy: 0.9516 - val_loss: 0.8376 - val_accuracy: 0.8328\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 0.1303 - accuracy: 0.9509 - val_loss: 0.7339 - val_accuracy: 0.8291\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.1243 - accuracy: 0.9529 - val_loss: 0.7549 - val_accuracy: 0.8337\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.1246 - accuracy: 0.9524 - val_loss: 0.7612 - val_accuracy: 0.8428\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.1143 - accuracy: 0.9554 - val_loss: 0.8212 - val_accuracy: 0.8433\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 1s 170ms/step - loss: 0.1218 - accuracy: 0.9528 - val_loss: 0.9697 - val_accuracy: 0.8340\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 1s 145ms/step - loss: 0.1106 - accuracy: 0.9577 - val_loss: 0.9218 - val_accuracy: 0.8341\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.1069 - accuracy: 0.9597 - val_loss: 0.9730 - val_accuracy: 0.8286\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.1085 - accuracy: 0.9587 - val_loss: 0.9334 - val_accuracy: 0.8323\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.1040 - accuracy: 0.9603 - val_loss: 0.8450 - val_accuracy: 0.8398\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 1s 165ms/step - loss: 0.1070 - accuracy: 0.9587 - val_loss: 0.8941 - val_accuracy: 0.8417\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 0.1064 - accuracy: 0.9592 - val_loss: 0.9296 - val_accuracy: 0.8343\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0983 - accuracy: 0.9624 - val_loss: 0.9644 - val_accuracy: 0.8321\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0995 - accuracy: 0.9618 - val_loss: 1.0263 - val_accuracy: 0.8329\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.1025 - accuracy: 0.9610 - val_loss: 0.9468 - val_accuracy: 0.8361\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0949 - accuracy: 0.9638 - val_loss: 0.9933 - val_accuracy: 0.8371\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.0995 - accuracy: 0.9620 - val_loss: 0.9596 - val_accuracy: 0.8434\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.0989 - accuracy: 0.9622 - val_loss: 0.9803 - val_accuracy: 0.8369\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0915 - accuracy: 0.9651 - val_loss: 1.0465 - val_accuracy: 0.8289\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.0948 - accuracy: 0.9636 - val_loss: 1.0938 - val_accuracy: 0.8318\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.0944 - accuracy: 0.9636 - val_loss: 0.9811 - val_accuracy: 0.8333\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.0931 - accuracy: 0.9640 - val_loss: 0.9902 - val_accuracy: 0.8316\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.0935 - accuracy: 0.9640 - val_loss: 1.0368 - val_accuracy: 0.8352\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.0905 - accuracy: 0.9651 - val_loss: 1.0433 - val_accuracy: 0.8360\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.0876 - accuracy: 0.9659 - val_loss: 1.0869 - val_accuracy: 0.8307\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.0873 - accuracy: 0.9662 - val_loss: 1.1475 - val_accuracy: 0.8302\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.0881 - accuracy: 0.9664 - val_loss: 1.0295 - val_accuracy: 0.8354\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.0845 - accuracy: 0.9677 - val_loss: 1.0087 - val_accuracy: 0.8396\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.0827 - accuracy: 0.9681 - val_loss: 1.0346 - val_accuracy: 0.8339\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0832 - accuracy: 0.9680 - val_loss: 1.0491 - val_accuracy: 0.8314\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 1s 152ms/step - loss: 0.0853 - accuracy: 0.9671 - val_loss: 1.1685 - val_accuracy: 0.8297\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0888 - accuracy: 0.9661 - val_loss: 1.0230 - val_accuracy: 0.8316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0817 - accuracy: 0.9686 - val_loss: 1.0343 - val_accuracy: 0.8342\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 1s 382ms/step - loss: 0.0808 - accuracy: 0.9685 - val_loss: 1.1322 - val_accuracy: 0.8334\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.0816 - accuracy: 0.9681 - val_loss: 1.1037 - val_accuracy: 0.8345\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 1s 184ms/step - loss: 0.0803 - accuracy: 0.9690 - val_loss: 1.0321 - val_accuracy: 0.8366\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 1s 179ms/step - loss: 0.0811 - accuracy: 0.9684 - val_loss: 1.1232 - val_accuracy: 0.8363\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 1s 216ms/step - loss: 0.0840 - accuracy: 0.9677 - val_loss: 1.0063 - val_accuracy: 0.8410\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.0854 - accuracy: 0.9670 - val_loss: 1.0990 - val_accuracy: 0.8288\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 1s 140ms/step - loss: 0.0797 - accuracy: 0.9692 - val_loss: 1.1373 - val_accuracy: 0.8261\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.0759 - accuracy: 0.9709 - val_loss: 1.1127 - val_accuracy: 0.8286\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 1s 140ms/step - loss: 0.0759 - accuracy: 0.9706 - val_loss: 1.1567 - val_accuracy: 0.8314\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.0785 - accuracy: 0.9696 - val_loss: 1.0141 - val_accuracy: 0.8400\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.0757 - accuracy: 0.9708 - val_loss: 1.0206 - val_accuracy: 0.8397\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0755 - accuracy: 0.9706 - val_loss: 1.0986 - val_accuracy: 0.8336\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.0713 - accuracy: 0.9719 - val_loss: 1.0813 - val_accuracy: 0.8289\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0707 - accuracy: 0.9725 - val_loss: 1.0920 - val_accuracy: 0.8311\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.0760 - accuracy: 0.9705 - val_loss: 1.0407 - val_accuracy: 0.8394\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 1s 115ms/step - loss: 0.0706 - accuracy: 0.9727 - val_loss: 1.0139 - val_accuracy: 0.8439\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.0822 - accuracy: 0.9682 - val_loss: 1.1089 - val_accuracy: 0.8365\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.0737 - accuracy: 0.9715 - val_loss: 1.0735 - val_accuracy: 0.8376\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 0.0727 - accuracy: 0.9717 - val_loss: 1.0752 - val_accuracy: 0.8361\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0713 - accuracy: 0.9721 - val_loss: 1.1024 - val_accuracy: 0.8312\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.0722 - accuracy: 0.9720 - val_loss: 1.1180 - val_accuracy: 0.8317\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.0748 - accuracy: 0.9712 - val_loss: 1.2000 - val_accuracy: 0.8230\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0776 - accuracy: 0.9694 - val_loss: 1.1227 - val_accuracy: 0.8340\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 1s 113ms/step - loss: 0.0713 - accuracy: 0.9720 - val_loss: 1.0457 - val_accuracy: 0.8380\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 1s 114ms/step - loss: 0.0714 - accuracy: 0.9723 - val_loss: 1.0394 - val_accuracy: 0.8401\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.0697 - accuracy: 0.9728 - val_loss: 1.0281 - val_accuracy: 0.8430\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.0737 - accuracy: 0.9715 - val_loss: 1.1194 - val_accuracy: 0.8323\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 1s 112ms/step - loss: 0.0699 - accuracy: 0.9730 - val_loss: 1.1224 - val_accuracy: 0.8239\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0701 - accuracy: 0.9727 - val_loss: 1.1662 - val_accuracy: 0.8280\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 0.0700 - accuracy: 0.9726 - val_loss: 1.1526 - val_accuracy: 0.8315\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 1s 165ms/step - loss: 0.0673 - accuracy: 0.9735 - val_loss: 1.1171 - val_accuracy: 0.8291\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 1s 145ms/step - loss: 0.0697 - accuracy: 0.9729 - val_loss: 1.1305 - val_accuracy: 0.8369\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 1s 180ms/step - loss: 0.0636 - accuracy: 0.9753 - val_loss: 1.1423 - val_accuracy: 0.8382\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.0650 - accuracy: 0.9743 - val_loss: 1.1409 - val_accuracy: 0.8319\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 1s 183ms/step - loss: 0.0692 - accuracy: 0.9731 - val_loss: 1.1730 - val_accuracy: 0.8345\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 1s 348ms/step - loss: 0.0657 - accuracy: 0.9744 - val_loss: 1.2528 - val_accuracy: 0.8321\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 1s 161ms/step - loss: 0.0689 - accuracy: 0.9731 - val_loss: 1.1819 - val_accuracy: 0.8285\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 0.0657 - accuracy: 0.9745 - val_loss: 1.1852 - val_accuracy: 0.8314\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0638 - accuracy: 0.9754 - val_loss: 1.2051 - val_accuracy: 0.8346\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0663 - accuracy: 0.9740 - val_loss: 1.1976 - val_accuracy: 0.8314\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 1s 151ms/step - loss: 0.0694 - accuracy: 0.9729 - val_loss: 1.1542 - val_accuracy: 0.8346\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 0.0654 - accuracy: 0.9744 - val_loss: 1.2081 - val_accuracy: 0.8337\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0717 - accuracy: 0.9718 - val_loss: 1.2160 - val_accuracy: 0.8316\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0619 - accuracy: 0.9758 - val_loss: 1.1909 - val_accuracy: 0.8311\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0665 - accuracy: 0.9737 - val_loss: 1.2765 - val_accuracy: 0.8312\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0653 - accuracy: 0.9744 - val_loss: 1.2176 - val_accuracy: 0.8327\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0613 - accuracy: 0.9755 - val_loss: 1.1834 - val_accuracy: 0.8300\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0632 - accuracy: 0.9755 - val_loss: 1.2514 - val_accuracy: 0.8273\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 1s 116ms/step - loss: 0.0612 - accuracy: 0.9760 - val_loss: 1.2088 - val_accuracy: 0.8284\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0591 - accuracy: 0.9769 - val_loss: 1.1964 - val_accuracy: 0.8296\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0597 - accuracy: 0.9765 - val_loss: 1.2168 - val_accuracy: 0.8326\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0630 - accuracy: 0.9749 - val_loss: 1.2694 - val_accuracy: 0.8332\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0607 - accuracy: 0.9762 - val_loss: 1.2086 - val_accuracy: 0.8312\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0628 - accuracy: 0.9755 - val_loss: 1.2083 - val_accuracy: 0.8335\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0592 - accuracy: 0.9765 - val_loss: 1.2452 - val_accuracy: 0.8360\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0593 - accuracy: 0.9768 - val_loss: 1.2228 - val_accuracy: 0.8326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0605 - accuracy: 0.9762 - val_loss: 1.3017 - val_accuracy: 0.8271\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 1s 129ms/step - loss: 0.0631 - accuracy: 0.9751 - val_loss: 1.2108 - val_accuracy: 0.8308\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.0610 - accuracy: 0.9759 - val_loss: 1.2524 - val_accuracy: 0.8319\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0567 - accuracy: 0.9780 - val_loss: 1.2813 - val_accuracy: 0.8314\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 1s 167ms/step - loss: 0.0583 - accuracy: 0.9773 - val_loss: 1.2453 - val_accuracy: 0.8335\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 0.0584 - accuracy: 0.9768 - val_loss: 1.2955 - val_accuracy: 0.8315\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.0559 - accuracy: 0.9779 - val_loss: 1.2539 - val_accuracy: 0.8321\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 1s 159ms/step - loss: 0.0569 - accuracy: 0.9774 - val_loss: 1.2114 - val_accuracy: 0.8276\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 1s 157ms/step - loss: 0.0575 - accuracy: 0.9776 - val_loss: 1.3049 - val_accuracy: 0.8305\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0566 - accuracy: 0.9777 - val_loss: 1.2513 - val_accuracy: 0.8296\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 0.0543 - accuracy: 0.9783 - val_loss: 1.2241 - val_accuracy: 0.8304\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0538 - accuracy: 0.9787 - val_loss: 1.2874 - val_accuracy: 0.8316\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0546 - accuracy: 0.9786 - val_loss: 1.2618 - val_accuracy: 0.8332\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0555 - accuracy: 0.9780 - val_loss: 1.3777 - val_accuracy: 0.8287\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0571 - accuracy: 0.9774 - val_loss: 1.2934 - val_accuracy: 0.8330\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0559 - accuracy: 0.9779 - val_loss: 1.3681 - val_accuracy: 0.8290\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0529 - accuracy: 0.9789 - val_loss: 1.3708 - val_accuracy: 0.8228\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0585 - accuracy: 0.9769 - val_loss: 1.2919 - val_accuracy: 0.8257\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0572 - accuracy: 0.9773 - val_loss: 1.4389 - val_accuracy: 0.8242\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0633 - accuracy: 0.9752 - val_loss: 1.2665 - val_accuracy: 0.8303\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0565 - accuracy: 0.9773 - val_loss: 1.2337 - val_accuracy: 0.8316\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0518 - accuracy: 0.9795 - val_loss: 1.2849 - val_accuracy: 0.8299\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0546 - accuracy: 0.9781 - val_loss: 1.2048 - val_accuracy: 0.8302\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0527 - accuracy: 0.9790 - val_loss: 1.2534 - val_accuracy: 0.8281\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0515 - accuracy: 0.9798 - val_loss: 1.2895 - val_accuracy: 0.8281\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0527 - accuracy: 0.9795 - val_loss: 1.2732 - val_accuracy: 0.8321\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0560 - accuracy: 0.9777 - val_loss: 1.3489 - val_accuracy: 0.8293\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0522 - accuracy: 0.9795 - val_loss: 1.3130 - val_accuracy: 0.8302\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0523 - accuracy: 0.9792 - val_loss: 1.3833 - val_accuracy: 0.8310\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.0546 - accuracy: 0.9786 - val_loss: 1.4173 - val_accuracy: 0.8272\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 1s 159ms/step - loss: 0.0529 - accuracy: 0.9787 - val_loss: 1.3623 - val_accuracy: 0.8281\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 1s 142ms/step - loss: 0.0546 - accuracy: 0.9787 - val_loss: 1.4372 - val_accuracy: 0.8269\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 1s 189ms/step - loss: 0.0572 - accuracy: 0.9769 - val_loss: 1.2744 - val_accuracy: 0.8289\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 1s 241ms/step - loss: 0.0535 - accuracy: 0.9790 - val_loss: 1.3142 - val_accuracy: 0.8308\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0513 - accuracy: 0.9796 - val_loss: 1.3642 - val_accuracy: 0.8322\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0521 - accuracy: 0.9796 - val_loss: 1.2280 - val_accuracy: 0.8368\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.0506 - accuracy: 0.9798 - val_loss: 1.2644 - val_accuracy: 0.8358\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.0494 - accuracy: 0.9806 - val_loss: 1.2953 - val_accuracy: 0.8331\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 1s 178ms/step - loss: 0.0504 - accuracy: 0.9800 - val_loss: 1.2801 - val_accuracy: 0.8322\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.0526 - accuracy: 0.9791 - val_loss: 1.4288 - val_accuracy: 0.8262\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0502 - accuracy: 0.9802 - val_loss: 1.3700 - val_accuracy: 0.8257\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 1s 138ms/step - loss: 0.0502 - accuracy: 0.9800 - val_loss: 1.3342 - val_accuracy: 0.8308\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 1s 131ms/step - loss: 0.0513 - accuracy: 0.9792 - val_loss: 1.4107 - val_accuracy: 0.8319\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0513 - accuracy: 0.9796 - val_loss: 1.3116 - val_accuracy: 0.8360\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0491 - accuracy: 0.9806 - val_loss: 1.3023 - val_accuracy: 0.8365\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0495 - accuracy: 0.9801 - val_loss: 1.3781 - val_accuracy: 0.8300\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0468 - accuracy: 0.9812 - val_loss: 1.3539 - val_accuracy: 0.8272\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0487 - accuracy: 0.9806 - val_loss: 1.3576 - val_accuracy: 0.8276\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0476 - accuracy: 0.9809 - val_loss: 1.3952 - val_accuracy: 0.8284\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0488 - accuracy: 0.9805 - val_loss: 1.3451 - val_accuracy: 0.8326\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.0461 - accuracy: 0.9817 - val_loss: 1.3610 - val_accuracy: 0.8357\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0494 - accuracy: 0.9801 - val_loss: 1.2729 - val_accuracy: 0.8372\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0491 - accuracy: 0.9802 - val_loss: 1.3133 - val_accuracy: 0.8324\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0466 - accuracy: 0.9814 - val_loss: 1.3913 - val_accuracy: 0.8271\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0507 - accuracy: 0.9798 - val_loss: 1.3007 - val_accuracy: 0.8307\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0489 - accuracy: 0.9807 - val_loss: 1.3335 - val_accuracy: 0.8334\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.0463 - accuracy: 0.9816 - val_loss: 1.3277 - val_accuracy: 0.8337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/1000\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 0.0465 - accuracy: 0.9813 - val_loss: 1.3072 - val_accuracy: 0.8327\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0487 - accuracy: 0.9807 - val_loss: 1.3661 - val_accuracy: 0.8316\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 1s 152ms/step - loss: 0.0484 - accuracy: 0.9809 - val_loss: 1.3286 - val_accuracy: 0.8300\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 1s 165ms/step - loss: 0.0467 - accuracy: 0.9816 - val_loss: 1.2969 - val_accuracy: 0.8344\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0472 - accuracy: 0.9811 - val_loss: 1.3357 - val_accuracy: 0.8345\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0453 - accuracy: 0.9821 - val_loss: 1.3350 - val_accuracy: 0.8327\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 1s 154ms/step - loss: 0.0457 - accuracy: 0.9819 - val_loss: 1.2886 - val_accuracy: 0.8327\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0452 - accuracy: 0.9820 - val_loss: 1.2990 - val_accuracy: 0.8320\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 0.0455 - accuracy: 0.9818 - val_loss: 1.3696 - val_accuracy: 0.8298\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0463 - accuracy: 0.9812 - val_loss: 1.3501 - val_accuracy: 0.8313\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0470 - accuracy: 0.9811 - val_loss: 1.3037 - val_accuracy: 0.8315\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 1s 148ms/step - loss: 0.0465 - accuracy: 0.9819 - val_loss: 1.3729 - val_accuracy: 0.8271\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.0450 - accuracy: 0.9821 - val_loss: 1.3486 - val_accuracy: 0.8279\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0454 - accuracy: 0.9820 - val_loss: 1.3916 - val_accuracy: 0.8277\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0454 - accuracy: 0.9818 - val_loss: 1.4018 - val_accuracy: 0.8283\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0450 - accuracy: 0.9819 - val_loss: 1.3355 - val_accuracy: 0.8282\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0452 - accuracy: 0.9818 - val_loss: 1.4150 - val_accuracy: 0.8285\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0449 - accuracy: 0.9818 - val_loss: 1.4345 - val_accuracy: 0.8275\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0427 - accuracy: 0.9827 - val_loss: 1.4005 - val_accuracy: 0.8290\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0449 - accuracy: 0.9818 - val_loss: 1.3461 - val_accuracy: 0.8338\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0461 - accuracy: 0.9815 - val_loss: 1.4027 - val_accuracy: 0.8338\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.0438 - accuracy: 0.9821 - val_loss: 1.3306 - val_accuracy: 0.8312\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0423 - accuracy: 0.9829 - val_loss: 1.4099 - val_accuracy: 0.8258\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0436 - accuracy: 0.9828 - val_loss: 1.5958 - val_accuracy: 0.8213\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0494 - accuracy: 0.9805 - val_loss: 1.4271 - val_accuracy: 0.8241\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 1s 148ms/step - loss: 0.0495 - accuracy: 0.9801 - val_loss: 1.5128 - val_accuracy: 0.8257\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 1s 257ms/step - loss: 0.0477 - accuracy: 0.9808 - val_loss: 1.3357 - val_accuracy: 0.8354\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 1s 154ms/step - loss: 0.0427 - accuracy: 0.9827 - val_loss: 1.2185 - val_accuracy: 0.8399\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 1s 134ms/step - loss: 0.0462 - accuracy: 0.9815 - val_loss: 1.3333 - val_accuracy: 0.8338\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 1s 206ms/step - loss: 0.0439 - accuracy: 0.9825 - val_loss: 1.3089 - val_accuracy: 0.8357\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.0428 - accuracy: 0.9830 - val_loss: 1.3258 - val_accuracy: 0.8319\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 1s 178ms/step - loss: 0.0423 - accuracy: 0.9831 - val_loss: 1.3913 - val_accuracy: 0.8302\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0429 - accuracy: 0.9822 - val_loss: 1.3425 - val_accuracy: 0.8318\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0415 - accuracy: 0.9836 - val_loss: 1.3709 - val_accuracy: 0.8313\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0430 - accuracy: 0.9829 - val_loss: 1.4002 - val_accuracy: 0.8339\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.0422 - accuracy: 0.9830 - val_loss: 1.3287 - val_accuracy: 0.8357\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0421 - accuracy: 0.9830 - val_loss: 1.3477 - val_accuracy: 0.8341\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 1s 153ms/step - loss: 0.0464 - accuracy: 0.9812 - val_loss: 1.3861 - val_accuracy: 0.8351\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.0457 - accuracy: 0.9817 - val_loss: 1.3225 - val_accuracy: 0.8358\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0418 - accuracy: 0.9833 - val_loss: 1.4008 - val_accuracy: 0.8342\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0411 - accuracy: 0.9834 - val_loss: 1.5152 - val_accuracy: 0.8338\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0434 - accuracy: 0.9828 - val_loss: 1.4660 - val_accuracy: 0.8346\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0400 - accuracy: 0.9841 - val_loss: 1.4265 - val_accuracy: 0.8343\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0405 - accuracy: 0.9838 - val_loss: 1.5082 - val_accuracy: 0.8350\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0413 - accuracy: 0.9835 - val_loss: 1.4952 - val_accuracy: 0.8344\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0395 - accuracy: 0.9840 - val_loss: 1.4925 - val_accuracy: 0.8328\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0419 - accuracy: 0.9832 - val_loss: 1.4482 - val_accuracy: 0.8350\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0391 - accuracy: 0.9842 - val_loss: 1.4431 - val_accuracy: 0.8362\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0409 - accuracy: 0.9835 - val_loss: 1.4111 - val_accuracy: 0.8334\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0407 - accuracy: 0.9832 - val_loss: 1.4292 - val_accuracy: 0.8322\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0397 - accuracy: 0.9840 - val_loss: 1.4947 - val_accuracy: 0.8321\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 1s 117ms/step - loss: 0.0399 - accuracy: 0.9838 - val_loss: 1.4565 - val_accuracy: 0.8338\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0391 - accuracy: 0.9843 - val_loss: 1.4346 - val_accuracy: 0.8326\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 1s 221ms/step - loss: 0.0394 - accuracy: 0.9841 - val_loss: 1.4880 - val_accuracy: 0.8290\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.0388 - accuracy: 0.9843 - val_loss: 1.5123 - val_accuracy: 0.8269\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.0396 - accuracy: 0.9841 - val_loss: 1.5251 - val_accuracy: 0.8246\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.0406 - accuracy: 0.9836 - val_loss: 1.4887 - val_accuracy: 0.8299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.0391 - accuracy: 0.9845 - val_loss: 1.5209 - val_accuracy: 0.8333\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 0.0393 - accuracy: 0.9841 - val_loss: 1.3620 - val_accuracy: 0.8370\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0413 - accuracy: 0.9833 - val_loss: 1.4505 - val_accuracy: 0.8325\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0377 - accuracy: 0.9846 - val_loss: 1.5915 - val_accuracy: 0.8269\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0423 - accuracy: 0.9831 - val_loss: 1.4220 - val_accuracy: 0.8306\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0401 - accuracy: 0.9837 - val_loss: 1.4481 - val_accuracy: 0.8315\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0387 - accuracy: 0.9844 - val_loss: 1.4801 - val_accuracy: 0.8329\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0422 - accuracy: 0.9830 - val_loss: 1.3651 - val_accuracy: 0.8346\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0471 - accuracy: 0.9812 - val_loss: 1.5642 - val_accuracy: 0.8247\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0434 - accuracy: 0.9826 - val_loss: 1.5396 - val_accuracy: 0.8280\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0407 - accuracy: 0.9838 - val_loss: 1.3166 - val_accuracy: 0.8349\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0420 - accuracy: 0.9830 - val_loss: 1.3421 - val_accuracy: 0.8336\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0412 - accuracy: 0.9833 - val_loss: 1.3795 - val_accuracy: 0.8367\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0393 - accuracy: 0.9840 - val_loss: 1.3698 - val_accuracy: 0.8353\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0419 - accuracy: 0.9831 - val_loss: 1.4558 - val_accuracy: 0.8272\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0413 - accuracy: 0.9830 - val_loss: 1.4212 - val_accuracy: 0.8298\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0377 - accuracy: 0.9846 - val_loss: 1.3789 - val_accuracy: 0.8360\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0453 - accuracy: 0.9821 - val_loss: 1.4411 - val_accuracy: 0.8308\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0446 - accuracy: 0.9819 - val_loss: 1.3636 - val_accuracy: 0.8342\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0381 - accuracy: 0.9844 - val_loss: 1.4376 - val_accuracy: 0.8344\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0406 - accuracy: 0.9836 - val_loss: 1.5305 - val_accuracy: 0.8284\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0373 - accuracy: 0.9847 - val_loss: 1.5013 - val_accuracy: 0.8265\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0388 - accuracy: 0.9841 - val_loss: 1.5804 - val_accuracy: 0.8281\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.0377 - accuracy: 0.9846 - val_loss: 1.6699 - val_accuracy: 0.8246\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 1s 170ms/step - loss: 0.0386 - accuracy: 0.9845 - val_loss: 1.5298 - val_accuracy: 0.8278\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 1s 182ms/step - loss: 0.0389 - accuracy: 0.9844 - val_loss: 1.4350 - val_accuracy: 0.8348\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 1s 129ms/step - loss: 0.0383 - accuracy: 0.9843 - val_loss: 1.4666 - val_accuracy: 0.8363\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 1s 206ms/step - loss: 0.0405 - accuracy: 0.9839 - val_loss: 1.4341 - val_accuracy: 0.8341\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0372 - accuracy: 0.9848 - val_loss: 1.5026 - val_accuracy: 0.8291\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 1s 164ms/step - loss: 0.0373 - accuracy: 0.9849 - val_loss: 1.5471 - val_accuracy: 0.8280\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0375 - accuracy: 0.9849 - val_loss: 1.5107 - val_accuracy: 0.8289\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 1s 131ms/step - loss: 0.0370 - accuracy: 0.9851 - val_loss: 1.4546 - val_accuracy: 0.8294\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 1s 118ms/step - loss: 0.0375 - accuracy: 0.9848 - val_loss: 1.4408 - val_accuracy: 0.8318\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0376 - accuracy: 0.9849 - val_loss: 1.4654 - val_accuracy: 0.8345\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0364 - accuracy: 0.9853 - val_loss: 1.4649 - val_accuracy: 0.8351\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0366 - accuracy: 0.9850 - val_loss: 1.4674 - val_accuracy: 0.8353\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.0367 - accuracy: 0.9852 - val_loss: 1.5525 - val_accuracy: 0.8314\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0378 - accuracy: 0.9844 - val_loss: 1.5165 - val_accuracy: 0.8308\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0353 - accuracy: 0.9855 - val_loss: 1.5461 - val_accuracy: 0.8295\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0348 - accuracy: 0.9859 - val_loss: 1.5385 - val_accuracy: 0.8295\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0345 - accuracy: 0.9859 - val_loss: 1.5301 - val_accuracy: 0.8299\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0352 - accuracy: 0.9855 - val_loss: 1.6047 - val_accuracy: 0.8301\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0350 - accuracy: 0.9861 - val_loss: 1.5767 - val_accuracy: 0.8309\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.0356 - accuracy: 0.9854 - val_loss: 1.5492 - val_accuracy: 0.8313\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0355 - accuracy: 0.9857 - val_loss: 1.5366 - val_accuracy: 0.8338\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0351 - accuracy: 0.9856 - val_loss: 1.5268 - val_accuracy: 0.8337\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0343 - accuracy: 0.9863 - val_loss: 1.5310 - val_accuracy: 0.8328\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0345 - accuracy: 0.9860 - val_loss: 1.5499 - val_accuracy: 0.8316\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0340 - accuracy: 0.9862 - val_loss: 1.5648 - val_accuracy: 0.8297\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0343 - accuracy: 0.9860 - val_loss: 1.5561 - val_accuracy: 0.8285\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 1s 168ms/step - loss: 0.0361 - accuracy: 0.9856 - val_loss: 1.6218 - val_accuracy: 0.8281\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 1s 142ms/step - loss: 0.0339 - accuracy: 0.9861 - val_loss: 1.6117 - val_accuracy: 0.8291\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0345 - accuracy: 0.9859 - val_loss: 1.6237 - val_accuracy: 0.8265\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 1s 200ms/step - loss: 0.0351 - accuracy: 0.9855 - val_loss: 1.6317 - val_accuracy: 0.8280\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 1s 187ms/step - loss: 0.0339 - accuracy: 0.9863 - val_loss: 1.5962 - val_accuracy: 0.8316\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.0335 - accuracy: 0.9863 - val_loss: 1.5862 - val_accuracy: 0.8324\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.0336 - accuracy: 0.9865 - val_loss: 1.5869 - val_accuracy: 0.8314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/1000\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 0.0335 - accuracy: 0.9864 - val_loss: 1.6122 - val_accuracy: 0.8319\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0337 - accuracy: 0.9863 - val_loss: 1.6150 - val_accuracy: 0.8318\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 1s 146ms/step - loss: 0.0338 - accuracy: 0.9863 - val_loss: 1.5787 - val_accuracy: 0.8299\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.0346 - accuracy: 0.9859 - val_loss: 1.6591 - val_accuracy: 0.8288\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0338 - accuracy: 0.9863 - val_loss: 1.6909 - val_accuracy: 0.8293\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0346 - accuracy: 0.9860 - val_loss: 1.5855 - val_accuracy: 0.8305\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0353 - accuracy: 0.9856 - val_loss: 1.5621 - val_accuracy: 0.8312\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0350 - accuracy: 0.9859 - val_loss: 1.6449 - val_accuracy: 0.8296\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0351 - accuracy: 0.9859 - val_loss: 1.6259 - val_accuracy: 0.8297\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0333 - accuracy: 0.9867 - val_loss: 1.6115 - val_accuracy: 0.8278\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0347 - accuracy: 0.9860 - val_loss: 1.6344 - val_accuracy: 0.8275\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0337 - accuracy: 0.9862 - val_loss: 1.6023 - val_accuracy: 0.8294\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0335 - accuracy: 0.9866 - val_loss: 1.5828 - val_accuracy: 0.8280\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0329 - accuracy: 0.9867 - val_loss: 1.6338 - val_accuracy: 0.8260\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0340 - accuracy: 0.9860 - val_loss: 1.7615 - val_accuracy: 0.8274\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0348 - accuracy: 0.9857 - val_loss: 1.6308 - val_accuracy: 0.8306\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0350 - accuracy: 0.9853 - val_loss: 1.5902 - val_accuracy: 0.8286\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0351 - accuracy: 0.9858 - val_loss: 1.5948 - val_accuracy: 0.8272\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0327 - accuracy: 0.9868 - val_loss: 1.6222 - val_accuracy: 0.8281\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0352 - accuracy: 0.9858 - val_loss: 1.6750 - val_accuracy: 0.8238\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 1s 192ms/step - loss: 0.0333 - accuracy: 0.9865 - val_loss: 1.6302 - val_accuracy: 0.8232\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.0338 - accuracy: 0.9863 - val_loss: 1.5433 - val_accuracy: 0.8283\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 1s 192ms/step - loss: 0.0346 - accuracy: 0.9858 - val_loss: 1.5956 - val_accuracy: 0.8270\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 1s 168ms/step - loss: 0.0325 - accuracy: 0.9866 - val_loss: 1.5621 - val_accuracy: 0.8282\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 1s 164ms/step - loss: 0.0321 - accuracy: 0.9870 - val_loss: 1.6020 - val_accuracy: 0.8284\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.0316 - accuracy: 0.9870 - val_loss: 1.6685 - val_accuracy: 0.8287\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 1s 198ms/step - loss: 0.0346 - accuracy: 0.9862 - val_loss: 1.6606 - val_accuracy: 0.8257\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 0.0321 - accuracy: 0.9869 - val_loss: 1.6574 - val_accuracy: 0.8254\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 0.0323 - accuracy: 0.9869 - val_loss: 1.6487 - val_accuracy: 0.8283\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0316 - accuracy: 0.9870 - val_loss: 1.6433 - val_accuracy: 0.8322\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0351 - accuracy: 0.9857 - val_loss: 1.5461 - val_accuracy: 0.8330\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0340 - accuracy: 0.9860 - val_loss: 1.6280 - val_accuracy: 0.8285\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0325 - accuracy: 0.9867 - val_loss: 1.7124 - val_accuracy: 0.8259\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0324 - accuracy: 0.9867 - val_loss: 1.6580 - val_accuracy: 0.8289\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0332 - accuracy: 0.9867 - val_loss: 1.6745 - val_accuracy: 0.8260\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0337 - accuracy: 0.9863 - val_loss: 1.6381 - val_accuracy: 0.8315\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0313 - accuracy: 0.9872 - val_loss: 1.6587 - val_accuracy: 0.8331\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0328 - accuracy: 0.9866 - val_loss: 1.6260 - val_accuracy: 0.8313\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0329 - accuracy: 0.9864 - val_loss: 1.5668 - val_accuracy: 0.8312\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0327 - accuracy: 0.9866 - val_loss: 1.6745 - val_accuracy: 0.8307\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0322 - accuracy: 0.9870 - val_loss: 1.6895 - val_accuracy: 0.8298\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0320 - accuracy: 0.9870 - val_loss: 1.6926 - val_accuracy: 0.8258\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0335 - accuracy: 0.9864 - val_loss: 1.6486 - val_accuracy: 0.8277\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0313 - accuracy: 0.9874 - val_loss: 1.7318 - val_accuracy: 0.8288\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0331 - accuracy: 0.9864 - val_loss: 1.7553 - val_accuracy: 0.8293\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.0341 - accuracy: 0.9861 - val_loss: 1.4921 - val_accuracy: 0.8344\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 1s 199ms/step - loss: 0.0331 - accuracy: 0.9866 - val_loss: 1.5319 - val_accuracy: 0.8357\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.0317 - accuracy: 0.9870 - val_loss: 1.7148 - val_accuracy: 0.8320\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0339 - accuracy: 0.9862 - val_loss: 1.5801 - val_accuracy: 0.8324\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 1s 253ms/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 1.6105 - val_accuracy: 0.8289\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 1s 163ms/step - loss: 0.0319 - accuracy: 0.9870 - val_loss: 1.6478 - val_accuracy: 0.8293\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 1s 204ms/step - loss: 0.0312 - accuracy: 0.9874 - val_loss: 1.5980 - val_accuracy: 0.8326\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.0328 - accuracy: 0.9868 - val_loss: 1.5939 - val_accuracy: 0.8316\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 1.5722 - val_accuracy: 0.8317\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 0.0315 - accuracy: 0.9873 - val_loss: 1.5747 - val_accuracy: 0.8344\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0313 - accuracy: 0.9875 - val_loss: 1.6768 - val_accuracy: 0.8338\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0310 - accuracy: 0.9873 - val_loss: 1.6857 - val_accuracy: 0.8299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0315 - accuracy: 0.9873 - val_loss: 1.6515 - val_accuracy: 0.8303\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0309 - accuracy: 0.9873 - val_loss: 1.7212 - val_accuracy: 0.8296\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0313 - accuracy: 0.9872 - val_loss: 1.7592 - val_accuracy: 0.8288\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0317 - accuracy: 0.9872 - val_loss: 1.7215 - val_accuracy: 0.8292\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0313 - accuracy: 0.9870 - val_loss: 1.7868 - val_accuracy: 0.8290\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0310 - accuracy: 0.9873 - val_loss: 1.6813 - val_accuracy: 0.8315\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0310 - accuracy: 0.9874 - val_loss: 1.6753 - val_accuracy: 0.8324\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0309 - accuracy: 0.9874 - val_loss: 1.7614 - val_accuracy: 0.8299\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0316 - accuracy: 0.9869 - val_loss: 1.7122 - val_accuracy: 0.8295\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 1.6744 - val_accuracy: 0.8320\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0293 - accuracy: 0.9880 - val_loss: 1.6339 - val_accuracy: 0.8330\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0295 - accuracy: 0.9880 - val_loss: 1.6516 - val_accuracy: 0.8332\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0293 - accuracy: 0.9880 - val_loss: 1.6722 - val_accuracy: 0.8330\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0292 - accuracy: 0.9879 - val_loss: 1.7247 - val_accuracy: 0.8321\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0293 - accuracy: 0.9880 - val_loss: 1.7220 - val_accuracy: 0.8327\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.0296 - accuracy: 0.9878 - val_loss: 1.6656 - val_accuracy: 0.8337\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 1s 149ms/step - loss: 0.0307 - accuracy: 0.9877 - val_loss: 1.6908 - val_accuracy: 0.8314\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0293 - accuracy: 0.9881 - val_loss: 1.6753 - val_accuracy: 0.8303\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 1s 220ms/step - loss: 0.0290 - accuracy: 0.9880 - val_loss: 1.7630 - val_accuracy: 0.8291\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.0296 - accuracy: 0.9880 - val_loss: 1.7959 - val_accuracy: 0.8288\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0303 - accuracy: 0.9876 - val_loss: 1.6881 - val_accuracy: 0.8294\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 1s 207ms/step - loss: 0.0303 - accuracy: 0.9876 - val_loss: 1.6995 - val_accuracy: 0.8293\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0302 - accuracy: 0.9874 - val_loss: 1.7015 - val_accuracy: 0.8309\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0294 - accuracy: 0.9881 - val_loss: 1.7010 - val_accuracy: 0.8302\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 1s 155ms/step - loss: 0.0290 - accuracy: 0.9881 - val_loss: 1.6902 - val_accuracy: 0.8300\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0286 - accuracy: 0.9884 - val_loss: 1.6889 - val_accuracy: 0.8297\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0302 - accuracy: 0.9877 - val_loss: 1.7072 - val_accuracy: 0.8285\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 1s 129ms/step - loss: 0.0285 - accuracy: 0.9884 - val_loss: 1.7614 - val_accuracy: 0.8281\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0299 - accuracy: 0.9881 - val_loss: 1.7679 - val_accuracy: 0.8269\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0292 - accuracy: 0.9879 - val_loss: 1.8315 - val_accuracy: 0.8255\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0293 - accuracy: 0.9881 - val_loss: 1.7798 - val_accuracy: 0.8280\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 1s 119ms/step - loss: 0.0289 - accuracy: 0.9881 - val_loss: 1.7386 - val_accuracy: 0.8302\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0286 - accuracy: 0.9885 - val_loss: 1.7912 - val_accuracy: 0.8316\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0287 - accuracy: 0.9884 - val_loss: 1.6982 - val_accuracy: 0.8326\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0284 - accuracy: 0.9883 - val_loss: 1.7339 - val_accuracy: 0.8307\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0288 - accuracy: 0.9883 - val_loss: 1.7953 - val_accuracy: 0.8270\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0288 - accuracy: 0.9883 - val_loss: 1.7318 - val_accuracy: 0.8280\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0301 - accuracy: 0.9876 - val_loss: 1.8982 - val_accuracy: 0.8240\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0295 - accuracy: 0.9882 - val_loss: 1.8361 - val_accuracy: 0.8252\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0285 - accuracy: 0.9883 - val_loss: 1.6527 - val_accuracy: 0.8285\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0294 - accuracy: 0.9879 - val_loss: 1.7088 - val_accuracy: 0.8298\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0283 - accuracy: 0.9884 - val_loss: 1.7186 - val_accuracy: 0.8325\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 0.0294 - accuracy: 0.9880 - val_loss: 1.6724 - val_accuracy: 0.8326\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 1s 192ms/step - loss: 0.0290 - accuracy: 0.9880 - val_loss: 1.7601 - val_accuracy: 0.8295\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 1s 177ms/step - loss: 0.0305 - accuracy: 0.9875 - val_loss: 1.7893 - val_accuracy: 0.8299\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 1s 187ms/step - loss: 0.0285 - accuracy: 0.9882 - val_loss: 1.7321 - val_accuracy: 0.8310\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 1s 179ms/step - loss: 0.0281 - accuracy: 0.9887 - val_loss: 1.7821 - val_accuracy: 0.8286\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0284 - accuracy: 0.9883 - val_loss: 1.7601 - val_accuracy: 0.8289\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 1s 257ms/step - loss: 0.0302 - accuracy: 0.9876 - val_loss: 1.9022 - val_accuracy: 0.8239\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 1s 163ms/step - loss: 0.0307 - accuracy: 0.9874 - val_loss: 1.8892 - val_accuracy: 0.8231\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 1.7254 - val_accuracy: 0.8284\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.0294 - accuracy: 0.9879 - val_loss: 1.7110 - val_accuracy: 0.8330\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0308 - accuracy: 0.9873 - val_loss: 1.6636 - val_accuracy: 0.8348\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0292 - accuracy: 0.9883 - val_loss: 1.6608 - val_accuracy: 0.8312\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 1s 161ms/step - loss: 0.0283 - accuracy: 0.9885 - val_loss: 1.7454 - val_accuracy: 0.8277\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0298 - accuracy: 0.9878 - val_loss: 1.7042 - val_accuracy: 0.8295\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0288 - accuracy: 0.9883 - val_loss: 1.7040 - val_accuracy: 0.8312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 555/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0290 - accuracy: 0.9881 - val_loss: 1.6855 - val_accuracy: 0.8336\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0312 - accuracy: 0.9873 - val_loss: 1.7378 - val_accuracy: 0.8305\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0298 - accuracy: 0.9878 - val_loss: 1.7770 - val_accuracy: 0.8255\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0293 - accuracy: 0.9881 - val_loss: 1.7829 - val_accuracy: 0.8278\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 1.7489 - val_accuracy: 0.8287\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0291 - accuracy: 0.9882 - val_loss: 1.7417 - val_accuracy: 0.8273\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0282 - accuracy: 0.9885 - val_loss: 1.6368 - val_accuracy: 0.8314\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 1s 145ms/step - loss: 0.0288 - accuracy: 0.9882 - val_loss: 1.7100 - val_accuracy: 0.8324\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 0.0274 - accuracy: 0.9890 - val_loss: 1.8003 - val_accuracy: 0.8293\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0288 - accuracy: 0.9879 - val_loss: 1.7003 - val_accuracy: 0.8285\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0282 - accuracy: 0.9886 - val_loss: 1.7202 - val_accuracy: 0.8288\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 1s 157ms/step - loss: 0.0273 - accuracy: 0.9888 - val_loss: 1.7532 - val_accuracy: 0.8287\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 1s 154ms/step - loss: 0.0294 - accuracy: 0.9881 - val_loss: 1.7326 - val_accuracy: 0.8273\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 0.0287 - accuracy: 0.9881 - val_loss: 1.9526 - val_accuracy: 0.8227\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 1s 186ms/step - loss: 0.0308 - accuracy: 0.9876 - val_loss: 1.8150 - val_accuracy: 0.8288\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0274 - accuracy: 0.9885 - val_loss: 1.7251 - val_accuracy: 0.8325\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 1s 154ms/step - loss: 0.0278 - accuracy: 0.9886 - val_loss: 1.7412 - val_accuracy: 0.8326\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 1s 164ms/step - loss: 0.0285 - accuracy: 0.9881 - val_loss: 1.6477 - val_accuracy: 0.8335\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 1s 182ms/step - loss: 0.0279 - accuracy: 0.9886 - val_loss: 1.7908 - val_accuracy: 0.8297\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0271 - accuracy: 0.9890 - val_loss: 1.8147 - val_accuracy: 0.8287\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 1s 155ms/step - loss: 0.0275 - accuracy: 0.9886 - val_loss: 1.7732 - val_accuracy: 0.8293\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 1s 138ms/step - loss: 0.0265 - accuracy: 0.9892 - val_loss: 1.7376 - val_accuracy: 0.8311\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0268 - accuracy: 0.9890 - val_loss: 1.7515 - val_accuracy: 0.8320\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0274 - accuracy: 0.9888 - val_loss: 1.8237 - val_accuracy: 0.8292\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 1s 156ms/step - loss: 0.0266 - accuracy: 0.9890 - val_loss: 1.7888 - val_accuracy: 0.8275\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0286 - accuracy: 0.9883 - val_loss: 1.7919 - val_accuracy: 0.8290\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0278 - accuracy: 0.9887 - val_loss: 1.8756 - val_accuracy: 0.8283\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0263 - accuracy: 0.9892 - val_loss: 1.8297 - val_accuracy: 0.8277\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0267 - accuracy: 0.9889 - val_loss: 1.8238 - val_accuracy: 0.8292\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0270 - accuracy: 0.9890 - val_loss: 1.9197 - val_accuracy: 0.8293\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0269 - accuracy: 0.9889 - val_loss: 1.8222 - val_accuracy: 0.8311\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0272 - accuracy: 0.9891 - val_loss: 1.7448 - val_accuracy: 0.8311\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0271 - accuracy: 0.9890 - val_loss: 1.8202 - val_accuracy: 0.8314\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0273 - accuracy: 0.9889 - val_loss: 1.8499 - val_accuracy: 0.8304\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0269 - accuracy: 0.9891 - val_loss: 1.7583 - val_accuracy: 0.8302\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0266 - accuracy: 0.9893 - val_loss: 1.8262 - val_accuracy: 0.8286\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0266 - accuracy: 0.9891 - val_loss: 1.8694 - val_accuracy: 0.8287\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 1s 171ms/step - loss: 0.0265 - accuracy: 0.9894 - val_loss: 1.7642 - val_accuracy: 0.8318\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 1s 219ms/step - loss: 0.0271 - accuracy: 0.9890 - val_loss: 1.8254 - val_accuracy: 0.8306\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.0269 - accuracy: 0.9890 - val_loss: 1.7749 - val_accuracy: 0.8287\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.0281 - accuracy: 0.9886 - val_loss: 1.7520 - val_accuracy: 0.8296\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 1s 155ms/step - loss: 0.0271 - accuracy: 0.9886 - val_loss: 1.8993 - val_accuracy: 0.8277\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0281 - accuracy: 0.9886 - val_loss: 1.7967 - val_accuracy: 0.8290\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.0267 - accuracy: 0.9890 - val_loss: 1.7491 - val_accuracy: 0.8305\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.0260 - accuracy: 0.9894 - val_loss: 1.7608 - val_accuracy: 0.8323\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 1s 178ms/step - loss: 0.0264 - accuracy: 0.9893 - val_loss: 1.7469 - val_accuracy: 0.8331\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 1s 152ms/step - loss: 0.0267 - accuracy: 0.9890 - val_loss: 1.7722 - val_accuracy: 0.8334\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0267 - accuracy: 0.9891 - val_loss: 1.8173 - val_accuracy: 0.8349\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 1s 129ms/step - loss: 0.0255 - accuracy: 0.9896 - val_loss: 1.7558 - val_accuracy: 0.8356\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0254 - accuracy: 0.9896 - val_loss: 1.7722 - val_accuracy: 0.8331\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 1s 146ms/step - loss: 0.0265 - accuracy: 0.9892 - val_loss: 1.8777 - val_accuracy: 0.8303\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0272 - accuracy: 0.9888 - val_loss: 1.7851 - val_accuracy: 0.8304\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0260 - accuracy: 0.9893 - val_loss: 1.8309 - val_accuracy: 0.8290\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0260 - accuracy: 0.9891 - val_loss: 1.8423 - val_accuracy: 0.8281\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0269 - accuracy: 0.9890 - val_loss: 1.6904 - val_accuracy: 0.8301\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0273 - accuracy: 0.9888 - val_loss: 1.7228 - val_accuracy: 0.8313\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0251 - accuracy: 0.9899 - val_loss: 1.7438 - val_accuracy: 0.8328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0257 - accuracy: 0.9894 - val_loss: 1.7148 - val_accuracy: 0.8333\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0282 - accuracy: 0.9884 - val_loss: 1.8316 - val_accuracy: 0.8295\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 1s 138ms/step - loss: 0.0262 - accuracy: 0.9891 - val_loss: 1.8608 - val_accuracy: 0.8306\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0251 - accuracy: 0.9896 - val_loss: 1.8174 - val_accuracy: 0.8316\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0263 - accuracy: 0.9892 - val_loss: 1.8148 - val_accuracy: 0.8298\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0256 - accuracy: 0.9894 - val_loss: 1.7988 - val_accuracy: 0.8307\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0252 - accuracy: 0.9896 - val_loss: 1.8727 - val_accuracy: 0.8309\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0255 - accuracy: 0.9897 - val_loss: 1.8479 - val_accuracy: 0.8310\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0260 - accuracy: 0.9894 - val_loss: 1.7234 - val_accuracy: 0.8336\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 1s 156ms/step - loss: 0.0251 - accuracy: 0.9898 - val_loss: 1.7883 - val_accuracy: 0.8328\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 1s 151ms/step - loss: 0.0253 - accuracy: 0.9894 - val_loss: 1.8356 - val_accuracy: 0.8330\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.0255 - accuracy: 0.9896 - val_loss: 1.7461 - val_accuracy: 0.8341\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 1s 142ms/step - loss: 0.0243 - accuracy: 0.9900 - val_loss: 1.7682 - val_accuracy: 0.8339\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.0257 - accuracy: 0.9892 - val_loss: 1.9031 - val_accuracy: 0.8318\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0252 - accuracy: 0.9896 - val_loss: 1.8664 - val_accuracy: 0.8308\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0242 - accuracy: 0.9900 - val_loss: 1.9322 - val_accuracy: 0.8284\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0249 - accuracy: 0.9899 - val_loss: 1.9698 - val_accuracy: 0.8268\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 1s 146ms/step - loss: 0.0257 - accuracy: 0.9895 - val_loss: 1.8677 - val_accuracy: 0.8279\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.0256 - accuracy: 0.9896 - val_loss: 1.9576 - val_accuracy: 0.8279\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 0.0247 - accuracy: 0.9898 - val_loss: 1.9931 - val_accuracy: 0.8285\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0255 - accuracy: 0.9896 - val_loss: 1.8314 - val_accuracy: 0.8306\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0256 - accuracy: 0.9894 - val_loss: 1.8471 - val_accuracy: 0.8321\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0243 - accuracy: 0.9900 - val_loss: 1.8414 - val_accuracy: 0.8332\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0245 - accuracy: 0.9900 - val_loss: 1.7581 - val_accuracy: 0.8340\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0259 - accuracy: 0.9894 - val_loss: 1.9477 - val_accuracy: 0.8291\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0257 - accuracy: 0.9894 - val_loss: 1.8224 - val_accuracy: 0.8309\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0233 - accuracy: 0.9905 - val_loss: 1.8154 - val_accuracy: 0.8318\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0239 - accuracy: 0.9902 - val_loss: 1.9068 - val_accuracy: 0.8307\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0252 - accuracy: 0.9897 - val_loss: 1.8249 - val_accuracy: 0.8305\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0249 - accuracy: 0.9897 - val_loss: 1.8276 - val_accuracy: 0.8294\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0242 - accuracy: 0.9901 - val_loss: 1.8700 - val_accuracy: 0.8301\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0245 - accuracy: 0.9899 - val_loss: 1.8124 - val_accuracy: 0.8309\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0240 - accuracy: 0.9901 - val_loss: 1.9156 - val_accuracy: 0.8288\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0246 - accuracy: 0.9899 - val_loss: 1.9875 - val_accuracy: 0.8284\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0239 - accuracy: 0.9901 - val_loss: 1.9639 - val_accuracy: 0.8291\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0242 - accuracy: 0.9901 - val_loss: 1.9606 - val_accuracy: 0.8284\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.0253 - accuracy: 0.9895 - val_loss: 1.8315 - val_accuracy: 0.8315\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 1s 241ms/step - loss: 0.0239 - accuracy: 0.9904 - val_loss: 1.8254 - val_accuracy: 0.8308\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.0244 - accuracy: 0.9899 - val_loss: 1.9384 - val_accuracy: 0.8283\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 0.0243 - accuracy: 0.9902 - val_loss: 1.8980 - val_accuracy: 0.8304\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 1s 229ms/step - loss: 0.0232 - accuracy: 0.9904 - val_loss: 1.9459 - val_accuracy: 0.8299\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0241 - accuracy: 0.9900 - val_loss: 1.9269 - val_accuracy: 0.8307\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.0255 - accuracy: 0.9894 - val_loss: 1.7577 - val_accuracy: 0.8321\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0253 - accuracy: 0.9895 - val_loss: 1.8306 - val_accuracy: 0.8303\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 1s 148ms/step - loss: 0.0237 - accuracy: 0.9903 - val_loss: 1.9678 - val_accuracy: 0.8284\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.0260 - accuracy: 0.9893 - val_loss: 1.8224 - val_accuracy: 0.8314\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0261 - accuracy: 0.9893 - val_loss: 1.9460 - val_accuracy: 0.8302\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0240 - accuracy: 0.9900 - val_loss: 1.9257 - val_accuracy: 0.8297\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0229 - accuracy: 0.9904 - val_loss: 1.8875 - val_accuracy: 0.8307\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.0236 - accuracy: 0.9902 - val_loss: 1.9354 - val_accuracy: 0.8289\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0231 - accuracy: 0.9906 - val_loss: 1.9672 - val_accuracy: 0.8271\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0244 - accuracy: 0.9900 - val_loss: 1.9344 - val_accuracy: 0.8289\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0234 - accuracy: 0.9906 - val_loss: 1.8971 - val_accuracy: 0.8291\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0237 - accuracy: 0.9901 - val_loss: 1.9409 - val_accuracy: 0.8282\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0245 - accuracy: 0.9897 - val_loss: 1.8720 - val_accuracy: 0.8315\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0231 - accuracy: 0.9906 - val_loss: 1.8992 - val_accuracy: 0.8329\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 1s 146ms/step - loss: 0.0233 - accuracy: 0.9904 - val_loss: 1.8792 - val_accuracy: 0.8335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 669/1000\n",
      "2/2 [==============================] - 1s 155ms/step - loss: 0.0235 - accuracy: 0.9904 - val_loss: 1.8493 - val_accuracy: 0.8315\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0233 - accuracy: 0.9903 - val_loss: 1.9309 - val_accuracy: 0.8302\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0237 - accuracy: 0.9903 - val_loss: 1.8630 - val_accuracy: 0.8313\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0235 - accuracy: 0.9904 - val_loss: 1.8272 - val_accuracy: 0.8323\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0226 - accuracy: 0.9907 - val_loss: 1.9031 - val_accuracy: 0.8314\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 1.8287 - val_accuracy: 0.8332\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.0230 - accuracy: 0.9903 - val_loss: 1.7925 - val_accuracy: 0.8326\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 1s 161ms/step - loss: 0.0231 - accuracy: 0.9906 - val_loss: 1.8754 - val_accuracy: 0.8297\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 1s 152ms/step - loss: 0.0231 - accuracy: 0.9905 - val_loss: 1.8738 - val_accuracy: 0.8300\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 0.0230 - accuracy: 0.9906 - val_loss: 1.9267 - val_accuracy: 0.8281\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 0.0232 - accuracy: 0.9906 - val_loss: 1.9278 - val_accuracy: 0.8279\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0231 - accuracy: 0.9906 - val_loss: 1.9638 - val_accuracy: 0.8290\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 1s 120ms/step - loss: 0.0231 - accuracy: 0.9905 - val_loss: 2.0179 - val_accuracy: 0.8277\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 0.0231 - accuracy: 0.9907 - val_loss: 1.9342 - val_accuracy: 0.8287\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 1s 157ms/step - loss: 0.0231 - accuracy: 0.9905 - val_loss: 1.9491 - val_accuracy: 0.8300\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 1s 145ms/step - loss: 0.0223 - accuracy: 0.9909 - val_loss: 1.9829 - val_accuracy: 0.8303\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 1s 132ms/step - loss: 0.0225 - accuracy: 0.9908 - val_loss: 1.9258 - val_accuracy: 0.8313\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.0223 - accuracy: 0.9908 - val_loss: 1.8812 - val_accuracy: 0.8317\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0239 - accuracy: 0.9903 - val_loss: 1.8307 - val_accuracy: 0.8344\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 0.0230 - accuracy: 0.9906 - val_loss: 1.9482 - val_accuracy: 0.8348\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0232 - accuracy: 0.9905 - val_loss: 1.9151 - val_accuracy: 0.8336\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0232 - accuracy: 0.9906 - val_loss: 1.8732 - val_accuracy: 0.8310\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0232 - accuracy: 0.9903 - val_loss: 2.0659 - val_accuracy: 0.8276\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0234 - accuracy: 0.9904 - val_loss: 2.0094 - val_accuracy: 0.8286\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0218 - accuracy: 0.9910 - val_loss: 1.9158 - val_accuracy: 0.8302\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0241 - accuracy: 0.9901 - val_loss: 2.0563 - val_accuracy: 0.8282\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0240 - accuracy: 0.9901 - val_loss: 2.0153 - val_accuracy: 0.8294\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0229 - accuracy: 0.9908 - val_loss: 1.9041 - val_accuracy: 0.8304\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0222 - accuracy: 0.9910 - val_loss: 1.9060 - val_accuracy: 0.8308\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.0229 - accuracy: 0.9905 - val_loss: 1.9860 - val_accuracy: 0.8321\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0236 - accuracy: 0.9903 - val_loss: 1.9026 - val_accuracy: 0.8336\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0228 - accuracy: 0.9905 - val_loss: 1.9438 - val_accuracy: 0.8308\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0232 - accuracy: 0.9903 - val_loss: 1.9927 - val_accuracy: 0.8309\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0225 - accuracy: 0.9908 - val_loss: 1.9544 - val_accuracy: 0.8316\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.0238 - accuracy: 0.9902 - val_loss: 2.0427 - val_accuracy: 0.8256\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 1s 185ms/step - loss: 0.0227 - accuracy: 0.9904 - val_loss: 2.0377 - val_accuracy: 0.8254\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 1s 159ms/step - loss: 0.0229 - accuracy: 0.9906 - val_loss: 1.9965 - val_accuracy: 0.8301\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 1s 160ms/step - loss: 0.0245 - accuracy: 0.9899 - val_loss: 2.0714 - val_accuracy: 0.8266\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 1s 224ms/step - loss: 0.0225 - accuracy: 0.9909 - val_loss: 1.9821 - val_accuracy: 0.8271\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 1s 198ms/step - loss: 0.0236 - accuracy: 0.9903 - val_loss: 1.9919 - val_accuracy: 0.8304\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.0224 - accuracy: 0.9908 - val_loss: 2.1744 - val_accuracy: 0.8305\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.0233 - accuracy: 0.9906 - val_loss: 2.0188 - val_accuracy: 0.8295\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0215 - accuracy: 0.9912 - val_loss: 1.9458 - val_accuracy: 0.8300\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 1s 175ms/step - loss: 0.0228 - accuracy: 0.9906 - val_loss: 2.0694 - val_accuracy: 0.8276\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 1s 168ms/step - loss: 0.0240 - accuracy: 0.9902 - val_loss: 1.9546 - val_accuracy: 0.8294\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0213 - accuracy: 0.9915 - val_loss: 1.9078 - val_accuracy: 0.8290\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0236 - accuracy: 0.9903 - val_loss: 2.0786 - val_accuracy: 0.8252\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 1s 164ms/step - loss: 0.0229 - accuracy: 0.9906 - val_loss: 1.9764 - val_accuracy: 0.8272\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0227 - accuracy: 0.9907 - val_loss: 1.9556 - val_accuracy: 0.8279\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 1s 142ms/step - loss: 0.0225 - accuracy: 0.9907 - val_loss: 2.0768 - val_accuracy: 0.8285\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0228 - accuracy: 0.9906 - val_loss: 1.9691 - val_accuracy: 0.8303\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0220 - accuracy: 0.9912 - val_loss: 1.9282 - val_accuracy: 0.8300\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 1s 407ms/step - loss: 0.0220 - accuracy: 0.9910 - val_loss: 2.0256 - val_accuracy: 0.8279\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0236 - accuracy: 0.9904 - val_loss: 1.9439 - val_accuracy: 0.8286\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.0232 - accuracy: 0.9905 - val_loss: 1.9911 - val_accuracy: 0.8297\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 1s 270ms/step - loss: 0.0232 - accuracy: 0.9905 - val_loss: 2.1055 - val_accuracy: 0.8286\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 1s 343ms/step - loss: 0.0246 - accuracy: 0.9899 - val_loss: 1.8277 - val_accuracy: 0.8319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 726/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0227 - accuracy: 0.9907 - val_loss: 1.8734 - val_accuracy: 0.8318\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 1s 176ms/step - loss: 0.0234 - accuracy: 0.9906 - val_loss: 2.0690 - val_accuracy: 0.8296\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 1s 138ms/step - loss: 0.0240 - accuracy: 0.9901 - val_loss: 1.9787 - val_accuracy: 0.8285\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 1s 140ms/step - loss: 0.0219 - accuracy: 0.9911 - val_loss: 2.0514 - val_accuracy: 0.8254\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 1s 176ms/step - loss: 0.0228 - accuracy: 0.9906 - val_loss: 2.0889 - val_accuracy: 0.8254\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 1s 173ms/step - loss: 0.0226 - accuracy: 0.9910 - val_loss: 2.0381 - val_accuracy: 0.8290\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0219 - accuracy: 0.9910 - val_loss: 2.0349 - val_accuracy: 0.8300\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0216 - accuracy: 0.9911 - val_loss: 2.0763 - val_accuracy: 0.8287\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 1s 155ms/step - loss: 0.0218 - accuracy: 0.9911 - val_loss: 2.0116 - val_accuracy: 0.8294\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 1s 164ms/step - loss: 0.0220 - accuracy: 0.9910 - val_loss: 2.1363 - val_accuracy: 0.8279\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0214 - accuracy: 0.9913 - val_loss: 2.1906 - val_accuracy: 0.8249\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 1s 140ms/step - loss: 0.0227 - accuracy: 0.9906 - val_loss: 1.9913 - val_accuracy: 0.8284\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0235 - accuracy: 0.9903 - val_loss: 2.1491 - val_accuracy: 0.8262\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 0.0211 - accuracy: 0.9913 - val_loss: 2.1700 - val_accuracy: 0.8250\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0227 - accuracy: 0.9907 - val_loss: 1.9596 - val_accuracy: 0.8275\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0227 - accuracy: 0.9906 - val_loss: 2.0565 - val_accuracy: 0.8257\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0217 - accuracy: 0.9913 - val_loss: 2.1701 - val_accuracy: 0.8243\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0222 - accuracy: 0.9909 - val_loss: 2.0044 - val_accuracy: 0.8264\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 1s 145ms/step - loss: 0.0219 - accuracy: 0.9910 - val_loss: 2.0476 - val_accuracy: 0.8245\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0208 - accuracy: 0.9916 - val_loss: 2.1370 - val_accuracy: 0.8234\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 1s 131ms/step - loss: 0.0213 - accuracy: 0.9912 - val_loss: 2.0046 - val_accuracy: 0.8259\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.0215 - accuracy: 0.9911 - val_loss: 2.0409 - val_accuracy: 0.8254\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.0216 - accuracy: 0.9913 - val_loss: 2.1269 - val_accuracy: 0.8248\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 1s 191ms/step - loss: 0.0213 - accuracy: 0.9911 - val_loss: 2.0361 - val_accuracy: 0.8268\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.0214 - accuracy: 0.9912 - val_loss: 2.0598 - val_accuracy: 0.8273\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0205 - accuracy: 0.9916 - val_loss: 2.1797 - val_accuracy: 0.8268\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 0.0240 - accuracy: 0.9900 - val_loss: 1.9173 - val_accuracy: 0.8301\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.0212 - accuracy: 0.9914 - val_loss: 1.9300 - val_accuracy: 0.8295\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.0212 - accuracy: 0.9914 - val_loss: 2.1388 - val_accuracy: 0.8274\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 1s 175ms/step - loss: 0.0223 - accuracy: 0.9907 - val_loss: 2.0020 - val_accuracy: 0.8296\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 1s 264ms/step - loss: 0.0206 - accuracy: 0.9916 - val_loss: 1.9494 - val_accuracy: 0.8302\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 1s 195ms/step - loss: 0.0213 - accuracy: 0.9914 - val_loss: 2.0661 - val_accuracy: 0.8279\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 0.0213 - accuracy: 0.9912 - val_loss: 2.0743 - val_accuracy: 0.8284\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 1s 274ms/step - loss: 0.0215 - accuracy: 0.9911 - val_loss: 2.0819 - val_accuracy: 0.8266\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 1s 252ms/step - loss: 0.0214 - accuracy: 0.9914 - val_loss: 2.0190 - val_accuracy: 0.8271\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 1s 154ms/step - loss: 0.0201 - accuracy: 0.9919 - val_loss: 2.1141 - val_accuracy: 0.8258\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 0.0208 - accuracy: 0.9914 - val_loss: 2.1267 - val_accuracy: 0.8252\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.0207 - accuracy: 0.9916 - val_loss: 2.0390 - val_accuracy: 0.8255\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 1s 151ms/step - loss: 0.0202 - accuracy: 0.9917 - val_loss: 2.0732 - val_accuracy: 0.8266\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 1s 173ms/step - loss: 0.0204 - accuracy: 0.9917 - val_loss: 2.1092 - val_accuracy: 0.8272\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 1s 129ms/step - loss: 0.0203 - accuracy: 0.9917 - val_loss: 2.0931 - val_accuracy: 0.8265\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0207 - accuracy: 0.9914 - val_loss: 2.0733 - val_accuracy: 0.8240\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0207 - accuracy: 0.9916 - val_loss: 2.0782 - val_accuracy: 0.8234\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0207 - accuracy: 0.9917 - val_loss: 2.0750 - val_accuracy: 0.8245\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0207 - accuracy: 0.9914 - val_loss: 2.0468 - val_accuracy: 0.8258\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 1s 148ms/step - loss: 0.0201 - accuracy: 0.9917 - val_loss: 2.1031 - val_accuracy: 0.8273\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0200 - accuracy: 0.9917 - val_loss: 2.1620 - val_accuracy: 0.8285\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0203 - accuracy: 0.9917 - val_loss: 2.1300 - val_accuracy: 0.8292\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 0.0195 - accuracy: 0.9921 - val_loss: 2.0885 - val_accuracy: 0.8271\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 0.0204 - accuracy: 0.9918 - val_loss: 2.1044 - val_accuracy: 0.8265\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 1s 253ms/step - loss: 0.0203 - accuracy: 0.9918 - val_loss: 2.1870 - val_accuracy: 0.8257\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 1s 163ms/step - loss: 0.0209 - accuracy: 0.9913 - val_loss: 2.1783 - val_accuracy: 0.8250\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 1s 172ms/step - loss: 0.0196 - accuracy: 0.9920 - val_loss: 2.1106 - val_accuracy: 0.8252\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 1s 190ms/step - loss: 0.0203 - accuracy: 0.9917 - val_loss: 2.1350 - val_accuracy: 0.8279\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 1s 191ms/step - loss: 0.0196 - accuracy: 0.9919 - val_loss: 2.1469 - val_accuracy: 0.8301\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 1s 140ms/step - loss: 0.0208 - accuracy: 0.9916 - val_loss: 2.0312 - val_accuracy: 0.8308\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 1s 169ms/step - loss: 0.0203 - accuracy: 0.9916 - val_loss: 2.0633 - val_accuracy: 0.8304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 783/1000\n",
      "2/2 [==============================] - 1s 152ms/step - loss: 0.0202 - accuracy: 0.9916 - val_loss: 2.1207 - val_accuracy: 0.8320\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 0.0197 - accuracy: 0.9920 - val_loss: 2.1566 - val_accuracy: 0.8316\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.0203 - accuracy: 0.9917 - val_loss: 2.0422 - val_accuracy: 0.8317\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 1s 190ms/step - loss: 0.0203 - accuracy: 0.9915 - val_loss: 2.0891 - val_accuracy: 0.8312\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.0204 - accuracy: 0.9917 - val_loss: 2.1233 - val_accuracy: 0.8301\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 1s 121ms/step - loss: 0.0197 - accuracy: 0.9920 - val_loss: 2.0834 - val_accuracy: 0.8298\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0193 - accuracy: 0.9920 - val_loss: 2.1240 - val_accuracy: 0.8278\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0205 - accuracy: 0.9917 - val_loss: 2.1296 - val_accuracy: 0.8296\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0201 - accuracy: 0.9919 - val_loss: 2.0941 - val_accuracy: 0.8300\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 0.0205 - accuracy: 0.9916 - val_loss: 2.0996 - val_accuracy: 0.8286\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 0.0202 - accuracy: 0.9917 - val_loss: 2.0896 - val_accuracy: 0.8301\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0195 - accuracy: 0.9919 - val_loss: 2.1579 - val_accuracy: 0.8304\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0197 - accuracy: 0.9919 - val_loss: 2.1902 - val_accuracy: 0.8305\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.0193 - accuracy: 0.9919 - val_loss: 2.1020 - val_accuracy: 0.8302\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0200 - accuracy: 0.9917 - val_loss: 2.1631 - val_accuracy: 0.8308\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0194 - accuracy: 0.9920 - val_loss: 2.2890 - val_accuracy: 0.8289\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0202 - accuracy: 0.9918 - val_loss: 2.1561 - val_accuracy: 0.8279\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 2.0843 - val_accuracy: 0.8273\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 0.0204 - accuracy: 0.9915 - val_loss: 2.2189 - val_accuracy: 0.8270\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.0192 - accuracy: 0.9922 - val_loss: 2.1357 - val_accuracy: 0.8283\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0195 - accuracy: 0.9918 - val_loss: 2.0280 - val_accuracy: 0.8283\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0194 - accuracy: 0.9920 - val_loss: 2.0398 - val_accuracy: 0.8267\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 1s 163ms/step - loss: 0.0201 - accuracy: 0.9919 - val_loss: 2.0225 - val_accuracy: 0.8292\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 1s 150ms/step - loss: 0.0187 - accuracy: 0.9923 - val_loss: 2.0479 - val_accuracy: 0.8313\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 1s 187ms/step - loss: 0.0193 - accuracy: 0.9921 - val_loss: 2.0118 - val_accuracy: 0.8315\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 1s 218ms/step - loss: 0.0192 - accuracy: 0.9922 - val_loss: 2.0719 - val_accuracy: 0.8311\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.0194 - accuracy: 0.9921 - val_loss: 2.0414 - val_accuracy: 0.8323\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0189 - accuracy: 0.9923 - val_loss: 2.0659 - val_accuracy: 0.8309\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0192 - accuracy: 0.9923 - val_loss: 2.1309 - val_accuracy: 0.8290\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 1s 147ms/step - loss: 0.0204 - accuracy: 0.9918 - val_loss: 2.1487 - val_accuracy: 0.8300\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0199 - accuracy: 0.9918 - val_loss: 2.1392 - val_accuracy: 0.8313\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 1s 139ms/step - loss: 0.0203 - accuracy: 0.9919 - val_loss: 2.0783 - val_accuracy: 0.8295\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0189 - accuracy: 0.9923 - val_loss: 2.1208 - val_accuracy: 0.8279\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 1s 145ms/step - loss: 0.0192 - accuracy: 0.9922 - val_loss: 2.1273 - val_accuracy: 0.8286\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0191 - accuracy: 0.9923 - val_loss: 2.1589 - val_accuracy: 0.8290\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0195 - accuracy: 0.9920 - val_loss: 2.1209 - val_accuracy: 0.8290\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0186 - accuracy: 0.9923 - val_loss: 2.0923 - val_accuracy: 0.8313\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0191 - accuracy: 0.9922 - val_loss: 2.1042 - val_accuracy: 0.8313\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0185 - accuracy: 0.9926 - val_loss: 2.1067 - val_accuracy: 0.8310\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0198 - accuracy: 0.9918 - val_loss: 2.0100 - val_accuracy: 0.8339\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 1s 145ms/step - loss: 0.0194 - accuracy: 0.9922 - val_loss: 2.0903 - val_accuracy: 0.8330\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0195 - accuracy: 0.9920 - val_loss: 2.1188 - val_accuracy: 0.8328\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0192 - accuracy: 0.9921 - val_loss: 1.9316 - val_accuracy: 0.8360\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 1s 133ms/step - loss: 0.0211 - accuracy: 0.9914 - val_loss: 2.0710 - val_accuracy: 0.8327\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 1s 131ms/step - loss: 0.0190 - accuracy: 0.9921 - val_loss: 2.1271 - val_accuracy: 0.8309\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.0201 - accuracy: 0.9919 - val_loss: 2.0017 - val_accuracy: 0.8319\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0203 - accuracy: 0.9917 - val_loss: 2.1226 - val_accuracy: 0.8289\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0195 - accuracy: 0.9920 - val_loss: 2.1133 - val_accuracy: 0.8321\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 1s 126ms/step - loss: 0.0186 - accuracy: 0.9924 - val_loss: 2.0199 - val_accuracy: 0.8349\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0196 - accuracy: 0.9920 - val_loss: 2.0568 - val_accuracy: 0.8334\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 1s 176ms/step - loss: 0.0187 - accuracy: 0.9921 - val_loss: 2.1304 - val_accuracy: 0.8314\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 0.0184 - accuracy: 0.9925 - val_loss: 2.1405 - val_accuracy: 0.8306\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 1s 168ms/step - loss: 0.0200 - accuracy: 0.9918 - val_loss: 2.2419 - val_accuracy: 0.8285\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 0.0191 - accuracy: 0.9922 - val_loss: 2.1586 - val_accuracy: 0.8301\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0183 - accuracy: 0.9924 - val_loss: 2.1051 - val_accuracy: 0.8323\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.0201 - accuracy: 0.9918 - val_loss: 2.2263 - val_accuracy: 0.8302\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 1s 182ms/step - loss: 0.0184 - accuracy: 0.9925 - val_loss: 2.2153 - val_accuracy: 0.8306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1000\n",
      "2/2 [==============================] - 1s 157ms/step - loss: 0.0187 - accuracy: 0.9924 - val_loss: 2.1119 - val_accuracy: 0.8323\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 1s 154ms/step - loss: 0.0190 - accuracy: 0.9922 - val_loss: 2.2006 - val_accuracy: 0.8312\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 1s 131ms/step - loss: 0.0181 - accuracy: 0.9926 - val_loss: 2.1082 - val_accuracy: 0.8325\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 0.0173 - accuracy: 0.9929 - val_loss: 2.0292 - val_accuracy: 0.8336\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 1s 134ms/step - loss: 0.0193 - accuracy: 0.9920 - val_loss: 2.1026 - val_accuracy: 0.8302\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.0186 - accuracy: 0.9926 - val_loss: 2.1493 - val_accuracy: 0.8288\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0175 - accuracy: 0.9929 - val_loss: 2.1566 - val_accuracy: 0.8288\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0188 - accuracy: 0.9922 - val_loss: 2.1874 - val_accuracy: 0.8287\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0185 - accuracy: 0.9925 - val_loss: 2.0798 - val_accuracy: 0.8299\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0192 - accuracy: 0.9923 - val_loss: 2.0223 - val_accuracy: 0.8309\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 1s 129ms/step - loss: 0.0184 - accuracy: 0.9925 - val_loss: 2.1009 - val_accuracy: 0.8306\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 1s 130ms/step - loss: 0.0185 - accuracy: 0.9923 - val_loss: 2.0314 - val_accuracy: 0.8314\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 2.0177 - val_accuracy: 0.8325\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0190 - accuracy: 0.9921 - val_loss: 2.1472 - val_accuracy: 0.8311\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0184 - accuracy: 0.9926 - val_loss: 2.1182 - val_accuracy: 0.8307\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 1s 129ms/step - loss: 0.0186 - accuracy: 0.9923 - val_loss: 2.1337 - val_accuracy: 0.8301\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0180 - accuracy: 0.9926 - val_loss: 2.2405 - val_accuracy: 0.8289\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 1s 131ms/step - loss: 0.0176 - accuracy: 0.9928 - val_loss: 2.2449 - val_accuracy: 0.8283\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 1s 143ms/step - loss: 0.0181 - accuracy: 0.9925 - val_loss: 2.2325 - val_accuracy: 0.8287\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 1s 165ms/step - loss: 0.0179 - accuracy: 0.9928 - val_loss: 2.2075 - val_accuracy: 0.8282\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 1s 189ms/step - loss: 0.0184 - accuracy: 0.9924 - val_loss: 2.2568 - val_accuracy: 0.8288\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.0184 - accuracy: 0.9926 - val_loss: 2.2850 - val_accuracy: 0.8316\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 1s 192ms/step - loss: 0.0182 - accuracy: 0.9928 - val_loss: 2.2806 - val_accuracy: 0.8316\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 1s 141ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 2.2243 - val_accuracy: 0.8311\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 1s 188ms/step - loss: 0.0188 - accuracy: 0.9923 - val_loss: 2.1696 - val_accuracy: 0.8310\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.0184 - accuracy: 0.9924 - val_loss: 2.2051 - val_accuracy: 0.8298\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0185 - accuracy: 0.9924 - val_loss: 2.2485 - val_accuracy: 0.8268\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 1s 215ms/step - loss: 0.0178 - accuracy: 0.9928 - val_loss: 2.2376 - val_accuracy: 0.8272\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 1s 137ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 2.3185 - val_accuracy: 0.8263\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 1s 128ms/step - loss: 0.0175 - accuracy: 0.9928 - val_loss: 2.2336 - val_accuracy: 0.8281\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0182 - accuracy: 0.9925 - val_loss: 2.2002 - val_accuracy: 0.8284\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 1s 123ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 2.2591 - val_accuracy: 0.8279\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 1s 127ms/step - loss: 0.0177 - accuracy: 0.9927 - val_loss: 2.2482 - val_accuracy: 0.8292\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0183 - accuracy: 0.9927 - val_loss: 2.1871 - val_accuracy: 0.8289\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 1s 135ms/step - loss: 0.0187 - accuracy: 0.9923 - val_loss: 2.2285 - val_accuracy: 0.8278\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 1s 151ms/step - loss: 0.0186 - accuracy: 0.9923 - val_loss: 2.1207 - val_accuracy: 0.8318\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 1s 124ms/step - loss: 0.0189 - accuracy: 0.9922 - val_loss: 2.2345 - val_accuracy: 0.8307\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 0.0186 - accuracy: 0.9924 - val_loss: 2.2033 - val_accuracy: 0.8309\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 1s 136ms/step - loss: 0.0176 - accuracy: 0.9929 - val_loss: 2.1469 - val_accuracy: 0.8314\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 1s 161ms/step - loss: 0.0188 - accuracy: 0.9924 - val_loss: 2.2269 - val_accuracy: 0.8299\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 1s 158ms/step - loss: 0.0177 - accuracy: 0.9926 - val_loss: 2.3502 - val_accuracy: 0.8283\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 1s 125ms/step - loss: 0.0185 - accuracy: 0.9924 - val_loss: 2.2583 - val_accuracy: 0.8285\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0181 - accuracy: 0.9928 - val_loss: 2.2911 - val_accuracy: 0.8263\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 1s 162ms/step - loss: 0.0187 - accuracy: 0.9924 - val_loss: 2.3436 - val_accuracy: 0.8254\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 1s 202ms/step - loss: 0.0174 - accuracy: 0.9929 - val_loss: 2.2712 - val_accuracy: 0.8260\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 1s 164ms/step - loss: 0.0178 - accuracy: 0.9927 - val_loss: 2.3321 - val_accuracy: 0.8241\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 1s 144ms/step - loss: 0.0182 - accuracy: 0.9926 - val_loss: 2.3560 - val_accuracy: 0.8262\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 1s 200ms/step - loss: 0.0177 - accuracy: 0.9928 - val_loss: 2.3768 - val_accuracy: 0.8273\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 1s 122ms/step - loss: 0.0177 - accuracy: 0.9929 - val_loss: 2.3225 - val_accuracy: 0.8282\n",
      "Epoch 889/1000\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.0188 - accuracy: 0.9924"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = X_train.shape[1]\n",
    "IMG_WIDTH  = X_train.shape[2]\n",
    "IMG_CHANNELS = X_train.shape[3]\n",
    "\n",
    "def get_model():\n",
    "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
    "\n",
    "model = get_model()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#If starting with pre-trained weights. \n",
    "#model.load_weights('???.hdf5')\n",
    "\n",
    "history = model.fit(X_train, y_train_cat, \n",
    "                    batch_size = 16, \n",
    "                    verbose=1, \n",
    "                    epochs=1000, \n",
    "                    validation_data=(X_test, y_test_cat), \n",
    "                    #class_weight=class_weights,\n",
    "                    shuffle=False)\n",
    "                    \n",
    "\n",
    "\n",
    "model.save('test.hdf5')\n",
    "model.save('sandstone_50_epochs_catXentropy_acc_with_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559df22",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(X_test, y_test_cat)\n",
    "print(\"Accuracy is = \", (acc * 100.0), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b51754",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'y', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c81e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################\n",
    "#model = get_model()\n",
    "#model.load_weights('sandstone_50_epochs_catXentropy_acc.hdf5')  \n",
    "model.load_weights('sandstone_50_epochs_catXentropy_acc_with_weights.hdf5')  \n",
    "\n",
    "#IOU\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_argmax=np.argmax(y_pred, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f44891",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "\n",
    "#Using built in keras function\n",
    "from keras.metrics import MeanIoU\n",
    "n_classes = 4\n",
    "IOU_keras = MeanIoU(num_classes=n_classes)  \n",
    "IOU_keras.update_state(y_test[:,:,:,0], y_pred_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0523d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To calculate I0U for each class...\n",
    "values = np.array(IOU_keras.get_weights()).reshape(n_classes, n_classes)\n",
    "print(values)\n",
    "class1_IoU = values[0,0]/(values[0,0] + values[0,1] + values[0,2] + values[0,3] + values[1,0]+ values[2,0]+ values[3,0])\n",
    "class2_IoU = values[1,1]/(values[1,1] + values[1,0] + values[1,2] + values[1,3] + values[0,1]+ values[2,1]+ values[3,1])\n",
    "class3_IoU = values[2,2]/(values[2,2] + values[2,0] + values[2,1] + values[2,3] + values[0,2]+ values[1,2]+ values[3,2])\n",
    "class4_IoU = values[3,3]/(values[3,3] + values[3,0] + values[3,1] + values[3,2] + values[0,3]+ values[1,3]+ values[2,3])\n",
    "\n",
    "print(\"IoU for class1 is: \", class1_IoU)\n",
    "print(\"IoU for class2 is: \", class2_IoU)\n",
    "print(\"IoU for class3 is: \", class3_IoU)\n",
    "print(\"IoU for class4 is: \", class4_IoU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f05581",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0, :,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_masks[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b275f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "#Predict on a few images\n",
    "#model = get_model()\n",
    "#model.load_weights('???.hdf5')  \n",
    "import random\n",
    "test_img_number = random.randint(0, len(X_test))\n",
    "test_img = X_test[test_img_number]\n",
    "ground_truth=y_test[test_img_number]\n",
    "test_img_norm=test_img[:,:,0][:,:,None]\n",
    "test_img_input=np.expand_dims(test_img_norm, 0)\n",
    "prediction = (model.predict(test_img_input))\n",
    "predicted_img=np.argmax(prediction, axis=3)[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95926fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(ground_truth[:,:,0], cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b6e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(predicted_img, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d0103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e55e1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e558b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5778a7ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50bede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175fe1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73945c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f8a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09821e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e653f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cd797298",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on large image\n",
    "\n",
    "#Apply a trained model on large image\n",
    "\n",
    "from patchify import patchify, unpatchify\n",
    "\n",
    "large_image = cv2.imread('original_images/2.png', 0)\n",
    "#This will split the image into small images of shape [3,3]\n",
    "patches = patchify(large_image, (128, 128), step=128)  #Step=256 for 256 patches means no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "f816bb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0 1\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "0 2\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "0 3\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0 4\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0 5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0 6\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "0 7\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1 0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1 1\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1 2\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1 3\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1 4\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1 5\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1 6\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1 7\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "2 0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2 1\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "2 2\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2 3\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "2 4\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "2 5\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2 6\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "2 7\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "3 0\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "3 1\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "3 2\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "3 3\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "3 4\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "3 5\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "3 6\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "3 7\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "4 0\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "4 1\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "4 2\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "4 3\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "4 4\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "4 5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "4 6\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "4 7\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "5 0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "5 1\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "5 2\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "5 3\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "5 4\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "5 5\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "5 6\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "5 7\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "6 0\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "6 1\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "6 2\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "6 3\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "6 4\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "6 5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "6 6\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "6 7\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "7 0\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "7 1\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "7 2\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "7 3\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "7 4\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "7 5\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "7 6\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "7 7\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m predicted_patches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(predicted_patches)\n\u001b[1;32m     16\u001b[0m predicted_patches_reshaped \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(predicted_patches, (patches\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], patches\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m128\u001b[39m,\u001b[38;5;241m128\u001b[39m) )\n\u001b[0;32m---> 18\u001b[0m reconstructed_image \u001b[38;5;241m=\u001b[39m \u001b[43munpatchify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_patches_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlarge_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(reconstructed_image, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/ml/Tensorflow_ENV/tfenv/lib/python3.9/site-packages/patchify/__init__.py:59\u001b[0m, in \u001b[0;36munpatchify\u001b[0;34m(patches, imsize)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(patches\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\n\u001b[1;32m     55\u001b[0m     imsize\n\u001b[1;32m     56\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe patches dimension is not equal to the original image size\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(patches\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unpatchify2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTuple\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimsize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(patches\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpatchify3d(patches, cast(Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m], imsize))\n",
      "File \u001b[0;32m~/Desktop/ml/Tensorflow_ENV/tfenv/lib/python3.9/site-packages/patchify/__init__.py:100\u001b[0m, in \u001b[0;36m_unpatchify2d\u001b[0;34m(patches, imsize)\u001b[0m\n\u001b[1;32m     97\u001b[0m image[i_o : i_o \u001b[38;5;241m+\u001b[39m p_h, j_o : j_o \u001b[38;5;241m+\u001b[39m p_w] \u001b[38;5;241m=\u001b[39m patches[i, j]\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m j \u001b[38;5;241m<\u001b[39m n_w \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 100\u001b[0m     j \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mj_o\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mp_w\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_w\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m n_h \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m n_w \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;66;03m# Go to next row\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((i_o \u001b[38;5;241m+\u001b[39m p_h) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m s_h, n_h \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predicted_patches = []\n",
    "for i in range(patches.shape[0]):\n",
    "    for j in range(patches.shape[1]):\n",
    "        print(i,j)\n",
    "        \n",
    "        single_patch = patches[i,j,:,:]       \n",
    "        single_patch_norm = np.expand_dims(normalize(np.array(single_patch), axis=1),2)\n",
    "        single_patch_input=np.expand_dims(single_patch_norm, 0)\n",
    "        single_patch_prediction = (model.predict(single_patch_input))\n",
    "        single_patch_predicted_img=np.argmax(single_patch_prediction, axis=3)[0,:,:]\n",
    "\n",
    "        predicted_patches.append(single_patch_predicted_img)\n",
    "\n",
    "predicted_patches = np.array(predicted_patches)\n",
    "\n",
    "predicted_patches_reshaped = np.reshape(predicted_patches, (patches.shape[0], patches.shape[1], 128,128) )\n",
    "\n",
    "reconstructed_image = unpatchify(predicted_patches_reshaped, large_image.shape)\n",
    "plt.imshow(reconstructed_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "507674e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2914e+04 1.0730e+03 1.0000e+00 6.2000e+01]\n",
      " [4.1180e+03 1.7292e+04 3.1400e+02 9.8700e+02]\n",
      " [0.0000e+00 8.1000e+01 5.6000e+01 0.0000e+00]\n",
      " [6.0000e+00 6.0700e+02 6.7000e+01 1.5740e+03]]\n",
      "IoU for class1 is:  0.81330305\n",
      "IoU for class2 is:  0.70660347\n",
      "IoU for class3 is:  0.10789981\n",
      "IoU for class4 is:  0.47653648\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[1;32m     21\u001b[0m test_img_number \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_test))\n\u001b[0;32m---> 22\u001b[0m test_img \u001b[38;5;241m=\u001b[39m \u001b[43mX_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_img_number\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m ground_truth\u001b[38;5;241m=\u001b[39my_test[test_img_number]\n\u001b[1;32m     24\u001b[0m test_img_norm\u001b[38;5;241m=\u001b[39mtest_img[:,:,\u001b[38;5;241m0\u001b[39m][:,:,\u001b[38;5;28;01mNone\u001b[39;00m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.imsave('data/results/segm.jpg', reconstructed_image, cmap='gray')\n",
    "\n",
    "plt.hist(reconstructed_image.flatten())  #Threshold everything above 0\n",
    "\n",
    "# final_prediction = (reconstructed_image > 0.01).astype(np.uint8)\n",
    "# plt.imshow(final_prediction)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(221)\n",
    "plt.title('Large Image')\n",
    "plt.imshow(large_image, cmap='gray')\n",
    "plt.subplot(222)\n",
    "plt.title('Prediction of large Image')\n",
    "plt.imshow(reconstructed_image, cmap='jet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8fe0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b92313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
